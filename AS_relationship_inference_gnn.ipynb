{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a438ac16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentina/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Reload modulos automaticamente\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from modules.gnn_models import GCN, GraphSAGE, GAT\n",
    "from modules.graph import Graph, create_files\n",
    "from modules.gnn import GNN\n",
    "\n",
    "\n",
    "\n",
    "# from modules.gnn import GNN\n",
    "# from modules.models import  ModelGraphSAGE, GraphSAGE, GCN, ModelGCN, ModelSAGESample #ModelGraphSAGE,GraphSAGE, GCN,ModelSAGESample,SAGE, ModelGCN\n",
    "# from modules.predictors import DotPredictor, MLPPredictor, MLPPredictorEmbeddings\n",
    "# from modules.graph_from_api import Graph_API\n",
    "# from dgl.sampling import pack_traces\n",
    "\n",
    "# import torch.nn.functional as F\n",
    "# from torch.optim import Adam\n",
    "# from torch.optim import SparseAdam\n",
    "# import itertools\n",
    "import dgl\n",
    "import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "# from utils import *\n",
    "# from modules.graph import Graph\n",
    "# import numpy as np\n",
    "import os\n",
    "# import fnmatch\n",
    "# import tqdm\n",
    "# import networkx as nx\n",
    "\n",
    "# import dgl.function as fn\n",
    "# from dgl.nn import DeepWalk\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from gensim.models import Word2Vec\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from bgp2vec.bgp2vec import BGP2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd38fdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versi贸n de DGL: 2.4.0+cu121\n",
      "Versi贸n de PyTorch: 2.3.0+cu121\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Versi贸n de DGL:\", dgl.__version__)\n",
    "print(\"Versi贸n de PyTorch:\", torch.__version__)\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "TOR_LABELS_DICT = {'P2P':0, 'C2P': 1,'P2C': 2}\n",
    "\n",
    "\n",
    "models = {\n",
    "    'GCN': GCN,\n",
    "    'GraphSAGE': GraphSAGE,\n",
    "    'GAT': GAT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82607622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las rutas de los archivos\n",
    "BASE_PATH = os.getcwd() + \"/data/\"\n",
    "RELATIONSHIPS_FILE  = BASE_PATH + \"CAIDA_AS_Relationships/Serial_1/20220701.as-rel.txt.bz2\"\n",
    "FEATURES_FILE = BASE_PATH + \"/node_feature_mio.csv\" #\"/node_features.csv\" \n",
    "rib_path = BASE_PATH + 'sanitized_rib.txt'\n",
    "dataset_graph_path = BASE_PATH + 'dgl_graph/'\n",
    "MAX_NUM_ROUTES = 1000000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0739ec",
   "metadata": {},
   "source": [
    "## Creacion Grafo \n",
    "Creamos un grafo nx y dgl, ademas de los archivos edges.csv y nodes.csv a partir de archivos ribs previamente creados o de archivo CAIDA AS Relationships.\n",
    "\n",
    "Crear esos archivos una unica vez con create_graph() una ves ya creados los archivos edges.csv y nodes.csv puedo ocupar directamente la funcion \n",
    "\n",
    "Se le puede indicar el maximo de bgp paths que se quiere (hehco para cuando se leen ribs no de caida) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c676bf3b",
   "metadata": {},
   "source": [
    "### CASO 1: RIBs\n",
    "* Creacion de grafo a partir de paths recolectados de las RIBs por BGPStream\n",
    "* Por ahora le asignamos a todos los nodos embeddings iniciales de de dimension 32 parte con puros 1s todos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d9b08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CARPETA CREADA]:  /home/valentina/Desktop/GIT/TrabajoTesis/data/dgl_graph/\n",
      "[Creando topologia desde /home/valentina/Desktop/GIT/TrabajoTesis/data/sanitized_rib.txt]\n",
      "[ARCHIVO EDGES.CSV CREADO]\n",
      "[NX Graph]:  DiGraph with 43183 nodes and 150200 edges\n",
      "[Agregando attr a nodos desde /home/valentina/Desktop/GIT/TrabajoTesis/data//node_features_mio.csv]\n",
      "[ARCHIVO NODES.CSV CREADO], 0 nodos sin features\n",
      "[NX Graph]:  DiGraph with 43183 nodes and 150200 edges\n",
      "nodes.csv edges.csv\n",
      "[Etiquetando aristas con CAIDA]\n",
      "[INFO] Se eliminaron 12915 aristas sin 'Relationship'\n",
      "[META CREADO]\n",
      "[NX Graph]:  DiGraph with 26167 nodes and 120328 edges\n",
      "[NX Graph]:  DiGraph with 25855 nodes and 120017 edges\n",
      "[NX Graph]:  DiGraph with 25847 nodes and 120009 edges\n",
      "[NX Graph] DiGraph with 25847 nodes and 120009 edges\n"
     ]
    }
   ],
   "source": [
    "# Definimos las listas de features\n",
    "\n",
    "# features_file = 'node_degrees' #'' # 'node_degrees' # las features que se le agregaran seran \n",
    "# features_file = base_path + \"/node_features.csv\"\n",
    "features_file = BASE_PATH + \"/node_features_mio.csv\"\n",
    "type = 'DiGraph'#\"DiGraph\" # MultiDiGraph\n",
    "graph_case1 = create_files(type, \n",
    "            dataset_graph_path,\n",
    "            file = rib_path, \n",
    "            features_file = features_file, \n",
    "            from_caida=False, \n",
    "            remove_degree=3,\n",
    "            debug=True,\n",
    "            label_edges_file = RELATIONSHIPS_FILE,\n",
    "            max_paths = MAX_NUM_ROUTES)\n",
    " \n",
    "print('[NX Graph]',graph_case1.nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0bd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = 'home/valentina/Desktop/GIT/TrabajoTesis/data/CAIDA_AS_Relationships/Serial_1/20220701.as-rel.txt.bz2' \\\n",
    "'as-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9b6441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28a54bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(pos_score,neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    )\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378e5024",
   "metadata": {},
   "source": [
    "### CASO 1: \n",
    "* Encoder : GNN -> (GCN , GraphSAGE, GAT)\n",
    "* Decoder : DotProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17508b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data into cached files.\n",
      "Graph(num_nodes=43183, num_edges=3351277,\n",
      "      ndata_schemes={'feat': Scheme(shape=(69,), dtype=torch.float32)}\n",
      "      edata_schemes={'Relationship': Scheme(shape=(), dtype=torch.float32)})\n",
      "[ATTR SHAPE]:  torch.Size([43183, 69])\n",
      "Generando 3351277 aristas negativas...\n",
      "Aristas negativas generadas: 3351276\n"
     ]
    }
   ],
   "source": [
    "gnn = GNN(debug=True)\n",
    "gnn.load_dataset(dataset_graph_path, force_reload=True)\n",
    "\n",
    "print('[ATTR SHAPE]: ',gnn.dgl_graph.ndata['feat'].shape)\n",
    "in_feats = gnn.dgl_graph.ndata['feat'].shape[1]\n",
    "gnn.split_graph_edges(train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d23f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "decorer = 'DotProduct'\n",
    "in_feats = gnn.dgl_graph.ndata['feat'].shape[1]\n",
    "hidden_feats = 32 \n",
    "out_feats = 16\n",
    "\n",
    "for model_name in models:\n",
    "\n",
    "    print(\"Training model: {}\".format(model_name))\n",
    "\n",
    "    model = models[model_name](\n",
    "        in_feats=in_feats,\n",
    "        hidden_feats=hidden_feats,\n",
    "        out_feats=out_feats)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # ----------- training -------------------------------- #\n",
    "\n",
    "    all_logits = []\n",
    "    for e in range(50):\n",
    "\n",
    "        # forward\n",
    "        model.train()\n",
    "        h = model.encode(gnn.train_g, gnn.train_g.ndata[\"feat\"])\n",
    "\n",
    "        pos_score = model.decodeDotProduct(gnn.train_pos_g, h)\n",
    "        neg_score = model.decodeDotProduct(gnn.train_neg_g, h)\n",
    "\n",
    "\n",
    "        loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 10 == 0:\n",
    "            print(\"In epoch {}, loss: {}\".format(e, loss))\n",
    "\n",
    "    # ----------- 5. check results ------------------------ #\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pos_score = model.decodeDotProduct(gnn.test_pos_g, h)\n",
    "        neg_score = model.decodeDotProduct(gnn.test_neg_g, h)\n",
    "        print(\"AUC\", compute_auc(pos_score, neg_score))\n",
    "    \n",
    "    # Guaradar el modelo\n",
    "    torch.save(model.state_dict(), f'data/model_emb_{model_name}.pth')\n",
    "\n",
    "    # Guardar los embeddings\n",
    "    torch.save(h, f\"data/embeddings_ribs_DP_{model_name}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5d054b",
   "metadata": {},
   "source": [
    "### CASO 2: \n",
    "* Encoder : GNN -> (GCN , GraphSAGE, GAT)\n",
    "* Decoder : MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f53cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
