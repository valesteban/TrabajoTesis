{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised training\n",
    "Aca crearemos embeddings paa un grafo de Internet, es decir represenaciones de los SA a partir de la topologia y atributos de los SA.\n",
    "\n",
    "Para esto tomamos 3 enfoques:\n",
    "\n",
    "\n",
    "*   Caso 1: Reconstruction Approach autoencoder\n",
    "*   Caso 2: Reconstruction Approach attribute Masking\n",
    "*   Caso 3: Task Generation Pre-calculated descriptor\n",
    "\n",
    "Para cada uno crearemos un ejemplo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentina/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importar librerias y RIBs\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from modules.gnn import GNN\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "rib_path = 'data/sanitized_rib.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grafo NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(rib_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[0;32m----> 9\u001b[0m         nodos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m|\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convertir a enteros\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(nodos, nodos[\u001b[38;5;241m1\u001b[39m:])  \u001b[38;5;66;03m# Crear pares consecutivos\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         nx_graph\u001b[38;5;241m.\u001b[39madd_edges_from(edges)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Crear un grafo dirigido (BGP usa rutas direccionales)\n",
    "nx_graph = nx.DiGraph()\n",
    "\n",
    "# Leer el archivo y agregar aristas\n",
    "with open(rib_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        nodos = list(map(int, line.strip().split(\"|\")))  # Convertir a enteros\n",
    "        edges = zip(nodos, nodos[1:])  # Crear pares consecutivos\n",
    "        nx_graph.add_edges_from(edges)\n",
    "\n",
    "# Imprimir información del grafo\n",
    "print(f\"Número de nodos: {nx_graph.number_of_nodes()}\")\n",
    "print(f\"Número de aristas: {nx_graph.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grafo DGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=394239, num_edges=1676722,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "\n",
    "src, dst = [], []\n",
    "\n",
    "# Leer el archivo y extraer aristas\n",
    "with open(rib_path, \"r\") as f:\n",
    "    count_path = 0\n",
    "    for line in f:\n",
    "        count_path += 1\n",
    "        line = line.strip()\n",
    "        if not line:  # Ignorar líneas vacías\n",
    "            continue\n",
    "        try:\n",
    "            nodos = list(map(int, line.split(\"|\")))\n",
    "            src.extend(nodos[:-1])  # Nodo de origen\n",
    "            dst.extend(nodos[1:])   # Nodo de destino\n",
    "        except ValueError as e:\n",
    "            print(f\"Error al procesar la línea: '{line}'. Error: {e}\")\n",
    "            continue\n",
    "        if count_path == 500000: #FIXME: cambiar pormientras para debug\n",
    "            break\n",
    "\n",
    "# Crear el grafo dirigido en DGL\n",
    "dgl_graph = dgl.graph((torch.tensor(src), torch.tensor(dst)))\n",
    "\n",
    "# Imprimir información del grafo\n",
    "print(dgl_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode-Decoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import CoraGraphDataset\n",
    "from dgl.dataloading import negative_sampler\n",
    "import dgl.function as fn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from dgl.nn import SAGEConv, GraphConv, GATConv, GINConv, GatedGCNConv, GatedGraphConv\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_negative_edges(dgl_graph, num_neg_samples): #FIXME: optimizar\n",
    "    \"\"\"\n",
    "    Genera aristas negativas para el grafo dado.\n",
    "    \"\"\"\n",
    "    print(f\"Generando {num_neg_samples} aristas negativas...\")\n",
    "    neg_src_u = []\n",
    "    neg_dst_v = []\n",
    "    num_nodes = dgl_graph.num_nodes()\n",
    "\n",
    "    for i in range(num_neg_samples):\n",
    "        src = np.random.randint(0, num_nodes)\n",
    "        dst = np.random.randint(0, num_nodes)\n",
    "        while dgl_graph.has_edges_between(src, dst):\n",
    "            src = np.random.randint(0, num_nodes)\n",
    "            dst = np.random.randint(0, num_nodes)\n",
    "        neg_src_u.append(src)\n",
    "        neg_dst_v.append(dst)\n",
    "\n",
    "        if i % 500000 == 0:\n",
    "            print(f\"Aristas negativas generadas: {i}\")\n",
    "\n",
    "    return torch.tensor(neg_src_u), torch.tensor(neg_dst_v)\n",
    "\n",
    "def compute_auc(pos_score,neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo GCN\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphConv(in_feats, hidden_feats)\n",
    "        self.conv2 = GraphConv(hidden_feats, out_feats)\n",
    "    \n",
    "    def encode(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "    \n",
    "    def decode(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            scores = g.edata['score']\n",
    "            return scores\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        return (z @ z.T) > 0\n",
    "    \n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
    "        super(GraphSAGE).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, hidden_feats)\n",
    "        self.conv2 = SAGEConv(hidden_feats, out_feats)\n",
    "    \n",
    "    def encode(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "    \n",
    "    def decode(self, in_feat, edge_index):\n",
    "        return (in_feat[edge_index[0]] * in_feat[edge_index[1]]).sum(dim=-1)\n",
    "    \n",
    "    def decode_all(self, z):\n",
    "        return (z @ z.T) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "u,v = dgl_graph.edges()\n",
    "\n",
    "# IDs de lo edges\n",
    "eids = np.arange(dgl_graph.num_edges()) \n",
    "# Shuffle the edges\n",
    "eids = np.random.permutation(eids)\n",
    "\n",
    "# Tamaño de train y test\n",
    "test_size = int(len(eids) * 0.1) \n",
    "train_size = dgl_graph.num_edges() - test_size \n",
    "\n",
    "# Selecciona los edges de test y train\n",
    "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "\n",
    "# Matriz de adyacencia\n",
    "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
    "\n",
    "# Generar aristas negativas \n",
    "# neg_u, neg_v = get_negative_edges(dgl_graph, dgl_graph.num_edges())\n",
    "\n",
    "\n",
    "# # Matriz de adyacencia negativa\n",
    "# adj_neg = 1 - adj.todense() - np.eye(dgl_graph.num_nodes())\n",
    "\n",
    "# # IDs de lso edges negativos\n",
    "# neg_u, neg_v = np.where(adj_neg != 0) \n",
    "\n",
    "# # Selecciono nodos aleatorios (misma cantidad que el numero de edges positivos)\n",
    "# neg_eids = np.random.choice(len(neg_u), dgl_graph.num_edges())\n",
    "\n",
    "# test_neg_u, test_neg_v = (\n",
    "#     neg_u[neg_eids[:test_size]],\n",
    "#     neg_v[neg_eids[:test_size]],\n",
    "# )\n",
    "# train_neg_u, train_neg_v = (\n",
    "#     neg_u[neg_eids[test_size:]],\n",
    "#     neg_v[neg_eids[test_size:]],\n",
    "# )\n",
    "\n",
    "# train_g = dgl.remove_edges(dgl_graph, eids[:test_size])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando 1676722 aristas negativas...\n",
      "Aristas negativas generadas: 0\n",
      "Aristas negativas generadas: 500000\n",
      "Aristas negativas generadas: 1000000\n",
      "Aristas negativas generadas: 1500000\n"
     ]
    }
   ],
   "source": [
    "neg_u, neg_v = get_negative_edges(dgl_graph, dgl_graph.num_edges())\n",
    "#  167.564 -> 30 seg  -> \n",
    "#  334.996 -> 50 seg -> 100.000 paths\n",
    "#1.676.722 -> 4 min 17 seg -> 500.000 paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neg_u, test_neg_v = (\n",
    "    neg_u[:test_size],\n",
    "    neg_v[:test_size],\n",
    ")\n",
    "\n",
    "train_neg_u, train_neg_v = (\n",
    "    neg_u[test_size:],\n",
    "    neg_v[test_size:],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([394239, 128])\n"
     ]
    }
   ],
   "source": [
    "# Agregar features aleatorias a los nodos FIXME: cambiar por features reales\n",
    "dgl_graph.ndata['feat'] = torch.ones(dgl_graph.num_nodes(), 128)\n",
    "print(dgl_graph.ndata['feat'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=394239, num_edges=1509050,\n",
       "      ndata_schemes={'feat': Scheme(shape=(128,), dtype=torch.float32)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar edges de test\n",
    "train_g = dgl.remove_edges(dgl_graph, eids[:test_size])\n",
    "train_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=dgl_graph.num_nodes())\n",
    "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=dgl_graph.num_nodes())    \n",
    "\n",
    "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=dgl_graph.num_nodes())\n",
    "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=dgl_graph.num_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: 128\n",
      "Epoch 1/100, Loss: 8.374835968017578\n",
      "Epoch 2/100, Loss: 3.7176010608673096\n",
      "Epoch 3/100, Loss: 1.881535291671753\n",
      "Epoch 4/100, Loss: 0.8457967638969421\n",
      "Epoch 5/100, Loss: 0.6943091154098511\n",
      "Epoch 6/100, Loss: 0.6931784749031067\n",
      "Epoch 7/100, Loss: 0.6931965351104736\n",
      "Epoch 8/100, Loss: 0.6932178139686584\n",
      "Epoch 9/100, Loss: 0.6932422518730164\n",
      "Epoch 10/100, Loss: 0.6932687163352966\n",
      "Epoch 11/100, Loss: 0.6932965517044067\n",
      "Epoch 12/100, Loss: 0.6933256983757019\n",
      "Epoch 13/100, Loss: 0.6933552026748657\n",
      "Epoch 14/100, Loss: 0.6933846473693848\n",
      "Epoch 15/100, Loss: 0.6934139728546143\n",
      "Epoch 16/100, Loss: 0.6934426426887512\n",
      "Epoch 17/100, Loss: 0.6934702396392822\n",
      "Epoch 18/100, Loss: 0.6934968829154968\n",
      "Epoch 19/100, Loss: 0.6935219764709473\n",
      "Epoch 20/100, Loss: 0.6935461759567261\n",
      "Epoch 21/100, Loss: 0.6935684680938721\n",
      "Epoch 22/100, Loss: 0.6935895681381226\n",
      "Epoch 23/100, Loss: 0.6936091184616089\n",
      "Epoch 24/100, Loss: 0.6936269402503967\n",
      "Epoch 25/100, Loss: 0.6936432123184204\n",
      "Epoch 26/100, Loss: 0.6936583518981934\n",
      "Epoch 27/100, Loss: 0.693671703338623\n",
      "Epoch 28/100, Loss: 0.6936837434768677\n",
      "Epoch 29/100, Loss: 0.6936941146850586\n",
      "Epoch 30/100, Loss: 0.6937035918235779\n",
      "Epoch 31/100, Loss: 0.6937117576599121\n",
      "Epoch 32/100, Loss: 0.6937187910079956\n",
      "Epoch 33/100, Loss: 0.6937248110771179\n",
      "Epoch 34/100, Loss: 0.6937294602394104\n",
      "Epoch 35/100, Loss: 0.6937333941459656\n",
      "Epoch 36/100, Loss: 0.6937364339828491\n",
      "Epoch 37/100, Loss: 0.693738579750061\n",
      "Epoch 38/100, Loss: 0.6937400698661804\n",
      "Epoch 39/100, Loss: 0.6937403678894043\n",
      "Epoch 40/100, Loss: 0.6937406659126282\n",
      "Epoch 41/100, Loss: 0.6937398910522461\n",
      "Epoch 42/100, Loss: 0.6937388777732849\n",
      "Epoch 43/100, Loss: 0.6937370300292969\n",
      "Epoch 44/100, Loss: 0.6937350630760193\n",
      "Epoch 45/100, Loss: 0.6937323212623596\n",
      "Epoch 46/100, Loss: 0.6937294602394104\n",
      "Epoch 47/100, Loss: 0.6937261819839478\n",
      "Epoch 48/100, Loss: 0.6937226057052612\n",
      "Epoch 49/100, Loss: 0.693718671798706\n",
      "Epoch 50/100, Loss: 0.6937143802642822\n",
      "Epoch 51/100, Loss: 0.6937103867530823\n",
      "Epoch 52/100, Loss: 0.6937054991722107\n",
      "Epoch 53/100, Loss: 0.6937008500099182\n",
      "Epoch 54/100, Loss: 0.6936959624290466\n",
      "Epoch 55/100, Loss: 0.6936909556388855\n",
      "Epoch 56/100, Loss: 0.6936859488487244\n",
      "Epoch 57/100, Loss: 0.6936807632446289\n",
      "Epoch 58/100, Loss: 0.6936753988265991\n",
      "Epoch 59/100, Loss: 0.6936700344085693\n",
      "Epoch 60/100, Loss: 0.6936647295951843\n",
      "Epoch 61/100, Loss: 0.6936590671539307\n",
      "Epoch 62/100, Loss: 0.6936537027359009\n",
      "Epoch 63/100, Loss: 0.6936482191085815\n",
      "Epoch 64/100, Loss: 0.6936426162719727\n",
      "Epoch 65/100, Loss: 0.6936370730400085\n",
      "Epoch 66/100, Loss: 0.6936315894126892\n",
      "Epoch 67/100, Loss: 0.6936261057853699\n",
      "Epoch 68/100, Loss: 0.6936206817626953\n",
      "Epoch 69/100, Loss: 0.6936152577400208\n",
      "Epoch 70/100, Loss: 0.693609893321991\n",
      "Epoch 71/100, Loss: 0.6936044096946716\n",
      "Epoch 72/100, Loss: 0.6935989260673523\n",
      "Epoch 73/100, Loss: 0.6935937404632568\n",
      "Epoch 74/100, Loss: 0.6935883164405823\n",
      "Epoch 75/100, Loss: 0.6935830116271973\n",
      "Epoch 76/100, Loss: 0.6935778856277466\n",
      "Epoch 77/100, Loss: 0.6935727596282959\n",
      "Epoch 78/100, Loss: 0.6935677528381348\n",
      "Epoch 79/100, Loss: 0.6935626864433289\n",
      "Epoch 80/100, Loss: 0.6935575604438782\n",
      "Epoch 81/100, Loss: 0.6935528516769409\n",
      "Epoch 82/100, Loss: 0.6935478448867798\n",
      "Epoch 83/100, Loss: 0.6935429573059082\n",
      "Epoch 84/100, Loss: 0.693538248538971\n",
      "Epoch 85/100, Loss: 0.6935334801673889\n",
      "Epoch 86/100, Loss: 0.6935287714004517\n",
      "Epoch 87/100, Loss: 0.6935243010520935\n",
      "Epoch 88/100, Loss: 0.6935197114944458\n",
      "Epoch 89/100, Loss: 0.6935151815414429\n",
      "Epoch 90/100, Loss: 0.6935107707977295\n",
      "Epoch 91/100, Loss: 0.6935064792633057\n",
      "Epoch 92/100, Loss: 0.6935020089149475\n",
      "Epoch 93/100, Loss: 0.693497896194458\n",
      "Epoch 94/100, Loss: 0.6934937238693237\n",
      "Epoch 95/100, Loss: 0.6934895515441895\n",
      "Epoch 96/100, Loss: 0.6934856176376343\n",
      "Epoch 97/100, Loss: 0.6934813857078552\n",
      "Epoch 98/100, Loss: 0.6934775114059448\n",
      "Epoch 99/100, Loss: 0.6934736371040344\n",
      "Epoch 100/100, Loss: 0.6934695839881897\n",
      "AUC 0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "in_feats = dgl_graph.ndata[\"feat\"].shape[1]\n",
    "print(f\"Input features: {in_feats}\")\n",
    "hidden_feats = 16\n",
    "out_feats = 16\n",
    "model = GCN( in_feats,hidden_feats, out_feats)\n",
    "\n",
    "# Agregar self-loops al grafo de entrenamiento\n",
    "train_g = dgl.add_self_loop(train_g) #TODO: Investigar sobre esta practica\n",
    "\n",
    "# ------ Set up loss y optimizer ------\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# ------ Set up loss y optimizer ------\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    model.train()\n",
    "\n",
    "    # Calcular embeddings\n",
    "    h = model.encode(train_g, train_g.ndata[\"feat\"])\n",
    "    \n",
    "    # Valor a aristas\n",
    "    pos_score = model.decode(train_pos_g, h)\n",
    "    neg_score = model.decode(train_neg_g, h)\n",
    "\n",
    "    \n",
    "\n",
    "    # loss\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    # Asegurar que labels tenga la misma forma que scores\n",
    "    labels = labels.view(-1, 1)  # Expandir dimensiones FIXME:\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(scores, labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    pos_score = model.decode(test_pos_g, h)\n",
    "    neg_score = model.decode(test_neg_g, h)\n",
    "    \n",
    "    print(f\"AUC\",compute_auc(pos_score, neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings guardados en 'node_embeddings.csv'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.05271</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>-0.037414</td>\n",
       "      <td>0.081488</td>\n",
       "      <td>-0.04819</td>\n",
       "      <td>-0.035787</td>\n",
       "      <td>0.00712</td>\n",
       "      <td>-0.076475</td>\n",
       "      <td>0.031041</td>\n",
       "      <td>-0.036488</td>\n",
       "      <td>-0.063112</td>\n",
       "      <td>-0.028331</td>\n",
       "      <td>0.080137</td>\n",
       "      <td>-0.068534</td>\n",
       "      <td>-0.053136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.05271</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>-0.037414</td>\n",
       "      <td>0.081488</td>\n",
       "      <td>-0.04819</td>\n",
       "      <td>-0.035787</td>\n",
       "      <td>0.00712</td>\n",
       "      <td>-0.076475</td>\n",
       "      <td>0.031041</td>\n",
       "      <td>-0.036488</td>\n",
       "      <td>-0.063112</td>\n",
       "      <td>-0.028331</td>\n",
       "      <td>0.080137</td>\n",
       "      <td>-0.068534</td>\n",
       "      <td>-0.053136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.05271</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>-0.037414</td>\n",
       "      <td>0.081488</td>\n",
       "      <td>-0.04819</td>\n",
       "      <td>-0.035787</td>\n",
       "      <td>0.00712</td>\n",
       "      <td>-0.076475</td>\n",
       "      <td>0.031041</td>\n",
       "      <td>-0.036488</td>\n",
       "      <td>-0.063112</td>\n",
       "      <td>-0.028331</td>\n",
       "      <td>0.080137</td>\n",
       "      <td>-0.068534</td>\n",
       "      <td>-0.053136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.05271</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>-0.037414</td>\n",
       "      <td>0.081488</td>\n",
       "      <td>-0.04819</td>\n",
       "      <td>-0.035787</td>\n",
       "      <td>0.00712</td>\n",
       "      <td>-0.076475</td>\n",
       "      <td>0.031041</td>\n",
       "      <td>-0.036488</td>\n",
       "      <td>-0.063112</td>\n",
       "      <td>-0.028331</td>\n",
       "      <td>0.080137</td>\n",
       "      <td>-0.068534</td>\n",
       "      <td>-0.053136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.05271</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>-0.037414</td>\n",
       "      <td>0.081488</td>\n",
       "      <td>-0.04819</td>\n",
       "      <td>-0.035787</td>\n",
       "      <td>0.00712</td>\n",
       "      <td>-0.076475</td>\n",
       "      <td>0.031041</td>\n",
       "      <td>-0.036488</td>\n",
       "      <td>-0.063112</td>\n",
       "      <td>-0.028331</td>\n",
       "      <td>0.080137</td>\n",
       "      <td>-0.068534</td>\n",
       "      <td>-0.053136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394234</th>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.05271</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>-0.037414</td>\n",
       "      <td>0.081488</td>\n",
       "      <td>-0.04819</td>\n",
       "      <td>-0.035787</td>\n",
       "      <td>0.00712</td>\n",
       "      <td>-0.076475</td>\n",
       "      <td>0.031041</td>\n",
       "      <td>-0.036488</td>\n",
       "      <td>-0.063112</td>\n",
       "      <td>-0.028331</td>\n",
       "      <td>0.080137</td>\n",
       "      <td>-0.068534</td>\n",
       "      <td>-0.053136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394235</th>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.05271</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>-0.037414</td>\n",
       "      <td>0.081488</td>\n",
       "      <td>-0.04819</td>\n",
       "      <td>-0.035787</td>\n",
       "      <td>0.00712</td>\n",
       "      <td>-0.076475</td>\n",
       "      <td>0.031041</td>\n",
       "      <td>-0.036488</td>\n",
       "      <td>-0.063112</td>\n",
       "      <td>-0.028331</td>\n",
       "      <td>0.080137</td>\n",
       "      <td>-0.068534</td>\n",
       "      <td>-0.053136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394236</th>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.05271</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>-0.037414</td>\n",
       "      <td>0.081488</td>\n",
       "      <td>-0.04819</td>\n",
       "      <td>-0.035787</td>\n",
       "      <td>0.00712</td>\n",
       "      <td>-0.076475</td>\n",
       "      <td>0.031041</td>\n",
       "      <td>-0.036488</td>\n",
       "      <td>-0.063112</td>\n",
       "      <td>-0.028331</td>\n",
       "      <td>0.080137</td>\n",
       "      <td>-0.068534</td>\n",
       "      <td>-0.053136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394237</th>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.05271</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>-0.037414</td>\n",
       "      <td>0.081488</td>\n",
       "      <td>-0.04819</td>\n",
       "      <td>-0.035787</td>\n",
       "      <td>0.00712</td>\n",
       "      <td>-0.076475</td>\n",
       "      <td>0.031041</td>\n",
       "      <td>-0.036488</td>\n",
       "      <td>-0.063112</td>\n",
       "      <td>-0.028331</td>\n",
       "      <td>0.080137</td>\n",
       "      <td>-0.068534</td>\n",
       "      <td>-0.053136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394238</th>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.05271</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>-0.037414</td>\n",
       "      <td>0.081488</td>\n",
       "      <td>-0.04819</td>\n",
       "      <td>-0.035787</td>\n",
       "      <td>0.00712</td>\n",
       "      <td>-0.076475</td>\n",
       "      <td>0.031041</td>\n",
       "      <td>-0.036488</td>\n",
       "      <td>-0.063112</td>\n",
       "      <td>-0.028331</td>\n",
       "      <td>0.080137</td>\n",
       "      <td>-0.068534</td>\n",
       "      <td>-0.053136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394239 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0        1         2         3         4        5         6   \\\n",
       "node_id                                                                       \n",
       "0        0.090226  0.05271  0.031951 -0.037414  0.081488 -0.04819 -0.035787   \n",
       "1        0.090226  0.05271  0.031951 -0.037414  0.081488 -0.04819 -0.035787   \n",
       "2        0.090226  0.05271  0.031951 -0.037414  0.081488 -0.04819 -0.035787   \n",
       "3        0.090226  0.05271  0.031951 -0.037414  0.081488 -0.04819 -0.035787   \n",
       "4        0.090226  0.05271  0.031951 -0.037414  0.081488 -0.04819 -0.035787   \n",
       "...           ...      ...       ...       ...       ...      ...       ...   \n",
       "394234   0.090226  0.05271  0.031951 -0.037414  0.081488 -0.04819 -0.035787   \n",
       "394235   0.090226  0.05271  0.031951 -0.037414  0.081488 -0.04819 -0.035787   \n",
       "394236   0.090226  0.05271  0.031951 -0.037414  0.081488 -0.04819 -0.035787   \n",
       "394237   0.090226  0.05271  0.031951 -0.037414  0.081488 -0.04819 -0.035787   \n",
       "394238   0.090226  0.05271  0.031951 -0.037414  0.081488 -0.04819 -0.035787   \n",
       "\n",
       "              7         8         9         10        11        12        13  \\\n",
       "node_id                                                                        \n",
       "0        0.00712 -0.076475  0.031041 -0.036488 -0.063112 -0.028331  0.080137   \n",
       "1        0.00712 -0.076475  0.031041 -0.036488 -0.063112 -0.028331  0.080137   \n",
       "2        0.00712 -0.076475  0.031041 -0.036488 -0.063112 -0.028331  0.080137   \n",
       "3        0.00712 -0.076475  0.031041 -0.036488 -0.063112 -0.028331  0.080137   \n",
       "4        0.00712 -0.076475  0.031041 -0.036488 -0.063112 -0.028331  0.080137   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "394234   0.00712 -0.076475  0.031041 -0.036488 -0.063112 -0.028331  0.080137   \n",
       "394235   0.00712 -0.076475  0.031041 -0.036488 -0.063112 -0.028331  0.080137   \n",
       "394236   0.00712 -0.076475  0.031041 -0.036488 -0.063112 -0.028331  0.080137   \n",
       "394237   0.00712 -0.076475  0.031041 -0.036488 -0.063112 -0.028331  0.080137   \n",
       "394238   0.00712 -0.076475  0.031041 -0.036488 -0.063112 -0.028331  0.080137   \n",
       "\n",
       "               14        15  \n",
       "node_id                      \n",
       "0       -0.068534 -0.053136  \n",
       "1       -0.068534 -0.053136  \n",
       "2       -0.068534 -0.053136  \n",
       "3       -0.068534 -0.053136  \n",
       "4       -0.068534 -0.053136  \n",
       "...           ...       ...  \n",
       "394234  -0.068534 -0.053136  \n",
       "394235  -0.068534 -0.053136  \n",
       "394236  -0.068534 -0.053136  \n",
       "394237  -0.068534 -0.053136  \n",
       "394238  -0.068534 -0.053136  \n",
       "\n",
       "[394239 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Guaradar el modelo\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Guardar los embeddings de los nodos después del entrenamiento\n",
    "with torch.no_grad():\n",
    "    # Calcular los embeddings finales\n",
    "    final_embeddings = model.encode(train_g, train_g.ndata[\"feat\"]).detach().cpu().numpy()\n",
    "\n",
    "    # Crear un DataFrame para guardar los embeddings\n",
    "    # Obtener ids de los nodos (ASN)\n",
    "    node_ids = train_g.nodes().numpy()\n",
    "\n",
    "    emb_df = pd.DataFrame(final_embeddings, index=node_ids)\n",
    "    emb_df.index.name = \"node_id\"\n",
    "\n",
    "    # Guardar en un archivo CSV\n",
    "    emb_df.to_csv(\"node_embeddings.csv\")\n",
    "    np.save(\"node_embeddings.npy\", final_embeddings)\n",
    "    print(\"Embeddings guardados en 'node_embeddings.csv'\")\n",
    "\n",
    "emb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHAPE] (394239, 16)\n",
      "[EMBEDDING] [ 0.09022641  0.0527095   0.03195057 -0.03741408  0.08148827 -0.04818971\n",
      " -0.03578674  0.00711954 -0.07647453  0.03104107 -0.0364881  -0.06311219\n",
      " -0.02833056  0.0801375  -0.06853358 -0.05313587]\n"
     ]
    }
   ],
   "source": [
    "# Cargar embeddings\n",
    "embeddings = np.load(\"node_embeddings.npy\")\n",
    "print(\"[SHAPE]\",embeddings.shape)\n",
    "print(\"[EMBEDDING]\",embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosas a tener consideraciom:\n",
    "- GNN al crear un grafo, crea tdoos los nodos que se encuentran en el rango entregado. De esta forma pueden quedar nodos aislados, sin embargo ento causa que no se puedan ir 'actualizando' pero al agregar self_loop se actualizan con si mismos y supondremos que con ello algun patron para este tipo de nodos.\n",
    "- La entrega de embeddings finales esta en orden el ASN de valor inferios hasta el ASN de valor maximo.\n",
    "- Lo guardamso en un .csv dondde se asocia 'node_id' con su embeddings y donde node_id es el ASN del Sistema Autonomo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_g.ndata['feat'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "Primero:\n",
    "* Crear grafo GNN a partir de AS rank y los atributos de ese otro dataset de antes.\n",
    "* Con esa informacion entrenar los embedings y luego pasarle esos embedigs a a la clasificacion\n",
    "\n",
    "Segundo:\n",
    "* Probra crear grafo con archivos oix \n",
    "* Luego entrenar para clasificacion\n",
    "\n",
    "Tercero:\n",
    "* Copiar la Red Neuronal que ocupa BGP2Vec\n",
    "* Probar con los embeddings anteriores probar la clasificacion. \n",
    "Si hay buenos resultados significa que nuestra MLP es muy basica/simple/poco compleja para atrapar las relaciones, identificar patrones. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
