{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Embeddings con GNN\n",
    "Aca crearemos embeddings paa un grafo de Internet, es decir represenaciones de los SA a partir de la topologia y atributos de los SA.\n",
    "\n",
    "Para esto tomamos 3 enfoques:\n",
    "\n",
    "\n",
    "*   [Caso 1] Reconstruction Approach autoencoder: A traves de la prediccion de aristas construimos los embeddings de los nodos.\n",
    "*   [Caso 1.1] Reconstruction Approach autoencoder: en ves de ocupar las bgp routes recolectadas de los ribs ocupamos las relaciones de AS rank y le damso attr a las aristas (es solo para probar que lo estemos ahciendo bien y las cosas tienen sentido)\n",
    "*   [Caso 2]: Reconstruction Approach attribute Masking:\n",
    "*   Caso 3: Task Generation Pre-calculated descriptor\n",
    "\n",
    "Para cada uno crearemos un ejemplo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install  dgl -f https://data.dgl.ai/wheels/torch-2.3/cu121/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from modules.gnn import GNN\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from modules.graph import Graph, create_files\n",
    "from modules.gnn import GNN\n",
    "from modules.gnn_models import GCN, GraphSAGE\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las rutas de los archivos\n",
    "BASE_PATH = os.getcwd() + \"/data/\"\n",
    "relationships_file = BASE_PATH + \"CAIDA_AS_Relationships/Serial_1/20220701.as-rel.txt.bz2\"\n",
    "features_file = BASE_PATH + \"/node_features.csv\"\n",
    "rib_path = BASE_PATH + 'sanitized_rib.txt'\n",
    "dataset_graph_path = BASE_PATH + 'dgl_graph/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion Grafo \n",
    "Creamos un grafo nx y dgl, ademas de los archivos edges.csv y nodes.csv a partir de archivos ribs previamente creados o de archivo CAIDA AS Relationships.\n",
    "\n",
    "Crear esos archivos una unica vez con create_graph() una ves ya creados los archivos edges.csv y nodes.csv puedo ocupar directamente la funcion \n",
    "\n",
    "Se le puede indicar el maximo de bgp paths que se quiere (hehco para cuando se leen ribs no de caida) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASO 1: RIBs\n",
    "* Creacion de grafo a partir de paths recolectados de las RIBs por BGPStream\n",
    "* Por ahora le asignamos a todos los nodos embeddings iniciales de de dimension 32 parte con puros 1s todos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaRPETA CREADA]:  /home/valentina/Desktop/GIT/TrabajoTesis/data/dgl_graph/\n",
      "[ARCHIVO EDGES.CSV CREADO]\n",
      "[NX Graph]:  MultiDiGraph with 36173 nodes and 330327 edges\n",
      "[TOPOLOGIA CREADA]\n",
      "[SAVE IN: /home/valentina/Desktop/GIT/TrabajoTesis/data/dgl_graph/nodes.csv]\n",
      "[FEATURES CREADOS]\n",
      "[META CREADO]\n",
      "[NX Graph]:  MultiDiGraph with 26185 nodes and 320339 edges\n",
      "[NX Graph]:  MultiDiGraph with 26088 nodes and 320242 edges\n",
      "[NX Graph]:  MultiDiGraph with 26088 nodes and 320242 edges\n",
      "[NX Graph] MultiDiGraph with 26088 nodes and 320242 edges\n"
     ]
    }
   ],
   "source": [
    "# Definimos las listas de features\n",
    "\n",
    "LIST_FEATURES_NO_CATEG = ['ASN', 'AS_rank_numberAsns', 'AS_rank_numberPrefixes', 'AS_rank_numberAddresses', 'AS_rank_total', 'AS_rank_customer',\n",
    "                 'AS_rank_peer', 'AS_rank_provider', 'peeringDB_ix_count', 'peeringDB_fac_count', 'AS_hegemony', 'cti_top', 'cti_origin']\n",
    "\n",
    "LIST_FEATURES_CATEG = ['AS_rank_continent',\n",
    "                        'peeringDB_info_ratio',\n",
    "                        'peeringDB_info_scope',\n",
    "                        'peeringDB_info_type',\n",
    "                        'peeringDB_policy_general'\n",
    "                        'ASDB_C1L1']\n",
    "\n",
    "list_feat = LIST_FEATURES_NO_CATEG + LIST_FEATURES_CATEG\n",
    "\n",
    "features_file = 'node_degrees' #'' # 'node_degrees' # las features que se le agregaran seran \n",
    "type = 'MultiDiGraph'#\"DiGraph\" # MultiDiGraph\n",
    "relationships_file\n",
    "MAX_PATHS = 100000\n",
    "graph_case1 = create_files(type, \n",
    "            dataset_graph_path,\n",
    "            file = rib_path, \n",
    "            features_file = features_file, \n",
    "            from_caida=False, \n",
    "            remove_degree=3,\n",
    "            debug=True,\n",
    "            max_paths = MAX_PATHS)\n",
    " \n",
    "print('[NX Graph]',graph_case1.nx_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 2\n",
    "* Creacion del grafo a partir de CAIDA AS Relationships (AS Rank) \n",
    "* Se les da atributos a los edges correspondientes al tipo de relacion que comparten\n",
    "* Es solo de prueba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaRPETA CREADA]:  /home/valentina/Desktop/GIT/TrabajoTesis/data/dgl_graph/\n",
      "[NX Graph]:  DiGraph with 74140 nodes and 379420 edges\n",
      "[TOPOLOGIA CREADA]\n",
      "[todos attr]\n",
      "[bbbbbbbbbbbbbbbbbbbbbb]\n",
      "[NX Graph]:  DiGraph with 74140 nodes and 379420 edges\n",
      "[FEATURES CREADOS]\n",
      "[META CREADO]\n",
      "[NX Graph]:  DiGraph with 46714 nodes and 351994 edges\n",
      "[NX Graph]:  DiGraph with 46237 nodes and 351517 edges\n",
      "[NX Graph]:  DiGraph with 46229 nodes and 351509 edges\n",
      "[NX Graph] DiGraph with 46229 nodes and 351509 edges\n"
     ]
    }
   ],
   "source": [
    "# Definimos las listas de features\n",
    "LIST_FEATURES_NO_CATEG = ['ASN', 'AS_rank_numberAsns', 'AS_rank_numberPrefixes', 'AS_rank_numberAddresses', 'AS_rank_total', 'AS_rank_customer',\n",
    "                 'AS_rank_peer', 'AS_rank_provider', 'peeringDB_ix_count', 'peeringDB_fac_count', 'AS_hegemony', 'cti_top', 'cti_origin']\n",
    "\n",
    "LIST_FEATURES_CATEG = ['AS_rank_continent',\n",
    "                        'peeringDB_info_ratio',\n",
    "                        'peeringDB_info_scope',\n",
    "                        'peeringDB_info_type',\n",
    "                        'peeringDB_policy_general'\n",
    "                        'ASDB_C1L1']\n",
    "\n",
    "list_feat = LIST_FEATURES_NO_CATEG + LIST_FEATURES_CATEG\n",
    "\n",
    "features_file =  'data/node_features.csv'  #'node_degrees' #'' # 'node_degrees' # las features que se le agregaran seran \n",
    "type = \"DiGraph\" # MultiDiGraph\n",
    "\n",
    "max_paths = 100000\n",
    "graph_case1 = create_files(type, \n",
    "             dataset_graph_path,\n",
    "             relationships_file, \n",
    "             features_file, \n",
    "             from_caida=True, \n",
    "             remove_degree=3,\n",
    "             debug=True,\n",
    "max_paths = None)\n",
    " \n",
    "print('[NX Graph]',graph_case1.nx_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode-Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import CoraGraphDataset\n",
    "from dgl.dataloading import negative_sampler\n",
    "import dgl.function as fn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from dgl.nn import SAGEConv, GraphConv, GATConv, GINConv, GatedGCNConv, GatedGraphConv\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "from dgl.nn import SAGEConv\n",
    "from dgl.nn import SAGEConv, GraphConv, GATConv, GINConv, GatedGCNConv, GatedGraphConv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(pos_score,neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    )\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link Prediction\n",
    "Encoder : GNN\n",
    "Decoder : DotProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data into cached files.\n",
      "Graph(num_nodes=74140, num_edges=351509,\n",
      "      ndata_schemes={'feat': Scheme(shape=(72,), dtype=torch.float32)}\n",
      "      edata_schemes={'Relationship': Scheme(shape=(), dtype=torch.int64)})\n",
      "[ATTR SHAPE]:  torch.Size([74140, 72])\n",
      "Generando 351509 aristas negativas...\n",
      "Aristas negativas generadas: 351508\n"
     ]
    }
   ],
   "source": [
    "gnn = GNN(debug=True)\n",
    "gnn.load_dataset(dataset_graph_path, force_reload=True)\n",
    "\n",
    "# FIXME: Cambiar, por mientras se estan agregando feat aleatorias o 1s a los nodos\n",
    "# gnn.dgl_graph.ndata['feat'] = torch.ones(gnn.dgl_graph.num_nodes(), 128)            # features de tamano 128\n",
    "\n",
    "print('[ATTR SHAPE]: ',gnn.dgl_graph.ndata['feat'].shape)\n",
    "\n",
    "gnn.split_graph(train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 1.8114488124847412\n",
      "In epoch 5, loss: 0.5880826115608215\n",
      "In epoch 10, loss: 0.5368225574493408\n",
      "In epoch 15, loss: 0.5133905410766602\n",
      "In epoch 20, loss: 0.5007092356681824\n",
      "In epoch 25, loss: 0.48712238669395447\n",
      "In epoch 30, loss: 0.47574564814567566\n",
      "In epoch 35, loss: 0.46585574746131897\n",
      "In epoch 40, loss: 0.4587332308292389\n",
      "In epoch 45, loss: 0.45330360531806946\n",
      "In epoch 50, loss: 0.4496583938598633\n",
      "In epoch 55, loss: 0.44653990864753723\n",
      "In epoch 60, loss: 0.44383367896080017\n",
      "In epoch 65, loss: 0.4414408206939697\n",
      "In epoch 70, loss: 0.439255952835083\n",
      "In epoch 75, loss: 0.43731144070625305\n",
      "In epoch 80, loss: 0.4355417788028717\n",
      "In epoch 85, loss: 0.43387046456336975\n",
      "In epoch 90, loss: 0.4323161542415619\n",
      "In epoch 95, loss: 0.4308710992336273\n",
      "AUC 0.9344419057524246\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = GraphSAGE(gnn.train_g.ndata[\"feat\"].shape[1], 16,16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# ----------- 4. training -------------------------------- #\n",
    "\n",
    "all_logits = []\n",
    "for e in range(100):\n",
    "    # forward\n",
    "    model.train()\n",
    "    h = model.encode(gnn.train_g, gnn.train_g.ndata[\"feat\"])\n",
    "\n",
    "    pos_score = model.decodeDotProduct(gnn.train_pos_g, h)\n",
    "    neg_score = model.decodeDotProduct(gnn.train_neg_g, h)\n",
    "\n",
    "\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print(\"In epoch {}, loss: {}\".format(e, loss))\n",
    "\n",
    "# ----------- 5. check results ------------------------ #\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "with torch.no_grad():\n",
    "    pos_score = model.decodeDotProduct(gnn.test_pos_g, h)\n",
    "    neg_score = model.decodeDotProduct(gnn.test_neg_g, h)\n",
    "    print(\"AUC\", compute_auc(pos_score, neg_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO] GraphSAGE(\n",
      "  (conv1): SAGEConv(\n",
      "    (feat_drop): Dropout(p=0.0, inplace=False)\n",
      "    (fc_neigh): Linear(in_features=72, out_features=16, bias=False)\n",
      "    (fc_self): Linear(in_features=72, out_features=16, bias=True)\n",
      "  )\n",
      "  (conv2): SAGEConv(\n",
      "    (feat_drop): Dropout(p=0.0, inplace=False)\n",
      "    (fc_neigh): Linear(in_features=16, out_features=16, bias=False)\n",
      "    (fc_self): Linear(in_features=16, out_features=16, bias=True)\n",
      "  )\n",
      "  (decoder): MLPPredictor(\n",
      "    (W1): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (W2): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ") \n",
      "[EMBEDDINGS] tensor([[ 0.0932,  0.1134,  0.0181,  ..., -0.1633,  0.1197, -0.2719],\n",
      "        [ 0.1709,  0.0605,  0.0149,  ..., -0.1122,  0.0548, -0.1721],\n",
      "        [ 0.4162,  0.0903,  0.0248,  ..., -0.4585,  0.0986, -0.5992],\n",
      "        ...,\n",
      "        [ 0.0691,  0.0790, -0.0193,  ..., -0.1449,  0.0954, -0.2131],\n",
      "        [ 0.0502, -0.0102, -0.0521,  ..., -0.0742,  0.0468, -0.0872],\n",
      "        [-0.2538,  0.0183,  0.0726,  ...,  0.0538,  0.0266,  0.0482]],\n",
      "       grad_fn=<AddBackward0>) \n"
     ]
    }
   ],
   "source": [
    "print(f'[MODELO] {model} ')\n",
    "print(f'[EMBEDDINGS] {h} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo y embeddings \n",
    "# Guaradar el modelo\n",
    "torch.save(model.state_dict(), f'data/model_emb.pth')\n",
    "\n",
    "# Guardar los embeddings\n",
    "torch.save(h, f\"data/embeddings.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link Prediction\n",
    "Encoder : GNN\n",
    "Decoder : MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data into cached files.\n",
      "Graph(num_nodes=36173, num_edges=320242,\n",
      "      ndata_schemes={'feat': Scheme(shape=(2,), dtype=torch.float32)}\n",
      "      edata_schemes={'Relationship': Scheme(shape=(), dtype=torch.float32)})\n",
      "[ATTR SHAPE]:  torch.Size([36173, 2])\n",
      "Generando 320242 aristas negativas...\n",
      "Aristas negativas generadas: 320241\n"
     ]
    }
   ],
   "source": [
    "gnn = GNN(debug=True)\n",
    "gnn.load_dataset(dataset_graph_path, force_reload=True)\n",
    "\n",
    "# FIXME: Cambiar, por mientras se estan agregando feat aleatorias o 1s a los nodos\n",
    "# gnn.dgl_graph.ndata['feat'] = torch.ones(gnn.dgl_graph.num_nodes(), 128)            # features de tamano 128\n",
    "\n",
    "print('[ATTR SHAPE]: ',gnn.dgl_graph.ndata['feat'].shape)\n",
    "\n",
    "gnn.split_graph(train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.7014414072036743\n",
      "In epoch 5, loss: 0.6320050954818726\n",
      "In epoch 10, loss: 0.4730013310909271\n",
      "In epoch 15, loss: 0.250716894865036\n",
      "In epoch 20, loss: 0.13942362368106842\n",
      "In epoch 25, loss: 0.11567464470863342\n",
      "In epoch 30, loss: 0.1040361300110817\n",
      "In epoch 35, loss: 0.09642818570137024\n",
      "In epoch 40, loss: 0.09165021777153015\n",
      "In epoch 45, loss: 0.08361601829528809\n",
      "In epoch 50, loss: 0.07863310724496841\n",
      "In epoch 55, loss: 0.07742946594953537\n",
      "In epoch 60, loss: 0.07598143815994263\n",
      "In epoch 65, loss: 0.07474548369646072\n",
      "In epoch 70, loss: 0.07381406426429749\n",
      "In epoch 75, loss: 0.07291460037231445\n",
      "In epoch 80, loss: 0.07191368192434311\n",
      "In epoch 85, loss: 0.07128756493330002\n",
      "In epoch 90, loss: 0.070730060338974\n",
      "In epoch 95, loss: 0.07016365975141525\n",
      "AUC 0.9950219820341152\n"
     ]
    }
   ],
   "source": [
    "model = GraphSAGE(gnn.train_g.ndata[\"feat\"].shape[1], 16,16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# ----------- 4. training -------------------------------- #\n",
    "\n",
    "all_logits = []\n",
    "for e in range(100):\n",
    "    # forward\n",
    "    model.train()\n",
    "    h = model.encode(gnn.train_g, gnn.train_g.ndata[\"feat\"])\n",
    "\n",
    "    pos_score = model.decodeMLP(gnn.train_pos_g, h)\n",
    "    neg_score = model.decodeMLP(gnn.train_neg_g, h)\n",
    "\n",
    "\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print(\"In epoch {}, loss: {}\".format(e, loss))\n",
    "\n",
    "# ----------- 5. check results ------------------------ #\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "with torch.no_grad():\n",
    "    pos_score = model.decodeMLP(gnn.test_pos_g, h)\n",
    "    neg_score = model.decodeMLP(gnn.test_neg_g, h)\n",
    "    print(\"AUC\", compute_auc(pos_score, neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.fc_neigh.weight torch.Size([16, 2])\n",
      "conv1.fc_self.weight torch.Size([16, 2])\n",
      "conv1.fc_self.bias torch.Size([16])\n",
      "conv2.fc_neigh.weight torch.Size([16, 16])\n",
      "conv2.fc_self.weight torch.Size([16, 16])\n",
      "conv2.fc_self.bias torch.Size([16])\n",
      "decoder.W1.weight torch.Size([16, 32])\n",
      "decoder.W1.bias torch.Size([16])\n",
      "decoder.W2.weight torch.Size([1, 16])\n",
      "decoder.W2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Se incluyen los parametros tanto de MLP como de la GNN\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar Modelo y Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guaradar el modelo\n",
    "torch.save(model.state_dict(), 'data/model_emb.pth')\n",
    "\n",
    "# Guardar los embeddings\n",
    "torch.save(h, \"data/embeddings.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings guardados en 'node_embeddings.csv'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.101930</td>\n",
       "      <td>-0.335221</td>\n",
       "      <td>-3.074711</td>\n",
       "      <td>2.228754</td>\n",
       "      <td>-0.627656</td>\n",
       "      <td>-2.087168</td>\n",
       "      <td>2.749624</td>\n",
       "      <td>-0.108119</td>\n",
       "      <td>-1.696507</td>\n",
       "      <td>3.432124</td>\n",
       "      <td>-1.217278</td>\n",
       "      <td>-3.109729</td>\n",
       "      <td>2.090653</td>\n",
       "      <td>-2.463471</td>\n",
       "      <td>3.261267</td>\n",
       "      <td>-0.414159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.723648</td>\n",
       "      <td>-1.042069</td>\n",
       "      <td>-2.855011</td>\n",
       "      <td>1.761993</td>\n",
       "      <td>-0.334552</td>\n",
       "      <td>-1.730516</td>\n",
       "      <td>3.329224</td>\n",
       "      <td>-0.171126</td>\n",
       "      <td>-2.141119</td>\n",
       "      <td>3.345304</td>\n",
       "      <td>-0.868315</td>\n",
       "      <td>-3.146378</td>\n",
       "      <td>2.222488</td>\n",
       "      <td>-2.328668</td>\n",
       "      <td>3.026546</td>\n",
       "      <td>-0.028456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.158578</td>\n",
       "      <td>-1.128411</td>\n",
       "      <td>-3.201206</td>\n",
       "      <td>2.089556</td>\n",
       "      <td>-0.243688</td>\n",
       "      <td>-2.558243</td>\n",
       "      <td>3.160474</td>\n",
       "      <td>1.796038</td>\n",
       "      <td>-1.859045</td>\n",
       "      <td>2.827035</td>\n",
       "      <td>-1.029408</td>\n",
       "      <td>-3.751191</td>\n",
       "      <td>1.974931</td>\n",
       "      <td>-3.294911</td>\n",
       "      <td>3.833996</td>\n",
       "      <td>-0.531082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.077238</td>\n",
       "      <td>-0.910498</td>\n",
       "      <td>-3.221866</td>\n",
       "      <td>2.284746</td>\n",
       "      <td>-0.425296</td>\n",
       "      <td>-2.518895</td>\n",
       "      <td>3.067572</td>\n",
       "      <td>1.671393</td>\n",
       "      <td>-1.717550</td>\n",
       "      <td>2.932030</td>\n",
       "      <td>-1.126791</td>\n",
       "      <td>-3.613750</td>\n",
       "      <td>2.083611</td>\n",
       "      <td>-3.193594</td>\n",
       "      <td>3.809445</td>\n",
       "      <td>-0.619963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.975382</td>\n",
       "      <td>-0.805138</td>\n",
       "      <td>-3.114366</td>\n",
       "      <td>2.234302</td>\n",
       "      <td>-0.293983</td>\n",
       "      <td>-2.377515</td>\n",
       "      <td>2.980376</td>\n",
       "      <td>1.467021</td>\n",
       "      <td>-1.709631</td>\n",
       "      <td>2.908147</td>\n",
       "      <td>-1.105135</td>\n",
       "      <td>-3.563770</td>\n",
       "      <td>2.021119</td>\n",
       "      <td>-3.159290</td>\n",
       "      <td>3.726334</td>\n",
       "      <td>-0.601326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36168</th>\n",
       "      <td>0.860783</td>\n",
       "      <td>-1.317075</td>\n",
       "      <td>-3.237432</td>\n",
       "      <td>2.151350</td>\n",
       "      <td>0.031120</td>\n",
       "      <td>-2.795558</td>\n",
       "      <td>3.234994</td>\n",
       "      <td>3.156262</td>\n",
       "      <td>-1.719627</td>\n",
       "      <td>2.397869</td>\n",
       "      <td>-1.008901</td>\n",
       "      <td>-4.016392</td>\n",
       "      <td>1.883370</td>\n",
       "      <td>-3.971356</td>\n",
       "      <td>4.242860</td>\n",
       "      <td>-0.700788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36169</th>\n",
       "      <td>-0.368163</td>\n",
       "      <td>1.001421</td>\n",
       "      <td>-1.172179</td>\n",
       "      <td>2.207545</td>\n",
       "      <td>-1.146080</td>\n",
       "      <td>-1.596958</td>\n",
       "      <td>0.281243</td>\n",
       "      <td>-0.243500</td>\n",
       "      <td>1.134093</td>\n",
       "      <td>1.264028</td>\n",
       "      <td>-0.823900</td>\n",
       "      <td>-1.051718</td>\n",
       "      <td>-0.904146</td>\n",
       "      <td>-1.968068</td>\n",
       "      <td>1.897566</td>\n",
       "      <td>-1.251757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36170</th>\n",
       "      <td>1.198884</td>\n",
       "      <td>-0.767427</td>\n",
       "      <td>-3.267465</td>\n",
       "      <td>2.391738</td>\n",
       "      <td>-0.707687</td>\n",
       "      <td>-2.478895</td>\n",
       "      <td>3.019535</td>\n",
       "      <td>1.173728</td>\n",
       "      <td>-1.692087</td>\n",
       "      <td>3.166048</td>\n",
       "      <td>-1.204719</td>\n",
       "      <td>-3.448300</td>\n",
       "      <td>2.203176</td>\n",
       "      <td>-2.884263</td>\n",
       "      <td>3.673004</td>\n",
       "      <td>-0.615303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36171</th>\n",
       "      <td>1.001862</td>\n",
       "      <td>-0.510832</td>\n",
       "      <td>-3.042523</td>\n",
       "      <td>2.209620</td>\n",
       "      <td>-0.383830</td>\n",
       "      <td>-2.157973</td>\n",
       "      <td>2.739654</td>\n",
       "      <td>0.726272</td>\n",
       "      <td>-1.620797</td>\n",
       "      <td>3.045597</td>\n",
       "      <td>-1.227402</td>\n",
       "      <td>-3.290534</td>\n",
       "      <td>2.098525</td>\n",
       "      <td>-2.784280</td>\n",
       "      <td>3.451292</td>\n",
       "      <td>-0.502860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36172</th>\n",
       "      <td>0.798523</td>\n",
       "      <td>-1.340431</td>\n",
       "      <td>-3.298937</td>\n",
       "      <td>2.231372</td>\n",
       "      <td>0.045777</td>\n",
       "      <td>-2.871834</td>\n",
       "      <td>3.280957</td>\n",
       "      <td>3.517978</td>\n",
       "      <td>-1.663943</td>\n",
       "      <td>2.330639</td>\n",
       "      <td>-1.024352</td>\n",
       "      <td>-4.090005</td>\n",
       "      <td>1.931069</td>\n",
       "      <td>-4.139738</td>\n",
       "      <td>4.372475</td>\n",
       "      <td>-0.755890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36173 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6   \\\n",
       "node_id                                                                         \n",
       "0        1.101930 -0.335221 -3.074711  2.228754 -0.627656 -2.087168  2.749624   \n",
       "1        1.723648 -1.042069 -2.855011  1.761993 -0.334552 -1.730516  3.329224   \n",
       "2        1.158578 -1.128411 -3.201206  2.089556 -0.243688 -2.558243  3.160474   \n",
       "3        1.077238 -0.910498 -3.221866  2.284746 -0.425296 -2.518895  3.067572   \n",
       "4        0.975382 -0.805138 -3.114366  2.234302 -0.293983 -2.377515  2.980376   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "36168    0.860783 -1.317075 -3.237432  2.151350  0.031120 -2.795558  3.234994   \n",
       "36169   -0.368163  1.001421 -1.172179  2.207545 -1.146080 -1.596958  0.281243   \n",
       "36170    1.198884 -0.767427 -3.267465  2.391738 -0.707687 -2.478895  3.019535   \n",
       "36171    1.001862 -0.510832 -3.042523  2.209620 -0.383830 -2.157973  2.739654   \n",
       "36172    0.798523 -1.340431 -3.298937  2.231372  0.045777 -2.871834  3.280957   \n",
       "\n",
       "               7         8         9         10        11        12        13  \\\n",
       "node_id                                                                         \n",
       "0       -0.108119 -1.696507  3.432124 -1.217278 -3.109729  2.090653 -2.463471   \n",
       "1       -0.171126 -2.141119  3.345304 -0.868315 -3.146378  2.222488 -2.328668   \n",
       "2        1.796038 -1.859045  2.827035 -1.029408 -3.751191  1.974931 -3.294911   \n",
       "3        1.671393 -1.717550  2.932030 -1.126791 -3.613750  2.083611 -3.193594   \n",
       "4        1.467021 -1.709631  2.908147 -1.105135 -3.563770  2.021119 -3.159290   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "36168    3.156262 -1.719627  2.397869 -1.008901 -4.016392  1.883370 -3.971356   \n",
       "36169   -0.243500  1.134093  1.264028 -0.823900 -1.051718 -0.904146 -1.968068   \n",
       "36170    1.173728 -1.692087  3.166048 -1.204719 -3.448300  2.203176 -2.884263   \n",
       "36171    0.726272 -1.620797  3.045597 -1.227402 -3.290534  2.098525 -2.784280   \n",
       "36172    3.517978 -1.663943  2.330639 -1.024352 -4.090005  1.931069 -4.139738   \n",
       "\n",
       "               14        15  \n",
       "node_id                      \n",
       "0        3.261267 -0.414159  \n",
       "1        3.026546 -0.028456  \n",
       "2        3.833996 -0.531082  \n",
       "3        3.809445 -0.619963  \n",
       "4        3.726334 -0.601326  \n",
       "...           ...       ...  \n",
       "36168    4.242860 -0.700788  \n",
       "36169    1.897566 -1.251757  \n",
       "36170    3.673004 -0.615303  \n",
       "36171    3.451292 -0.502860  \n",
       "36172    4.372475 -0.755890  \n",
       "\n",
       "[36173 rows x 16 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Guaradar el modelo\n",
    "# torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# # Guardar los embeddings de los nodos después del entrenamiento\n",
    "# with torch.no_grad():\n",
    "#     # Calcular los embeddings finales\n",
    "#     # final_embeddings = model.encode(train_g, train_g.ndata[\"feat\"]).detach().cpu().numpy()\n",
    "#     final_embeddings = h.detach().cpu().numpy()\n",
    "\n",
    "#     # Crear un DataFrame para guardar los embeddings\n",
    "#     # Obtener ids de los nodos (ASN)\n",
    "#     # node_ids = train_g.nodes().numpy()\n",
    "#     node_ids = gnn.dgl_graph.nodes().numpy()\n",
    "\n",
    "#     emb_df = pd.DataFrame(final_embeddings, index=node_ids)\n",
    "#     emb_df.index.name = \"node_id\"\n",
    "\n",
    "#     # Guardar en un archivo CSV\n",
    "#     emb_df.to_csv(\"node_embeddings.csv\")\n",
    "#     np.save(\"node_embeddings.npy\", final_embeddings)\n",
    "#     print(\"Embeddings guardados en 'node_embeddings.csv'\")\n",
    "\n",
    "# emb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHAPE] (36173, 16)\n",
      "[EMBEDDING] [ 1.1019298 -0.3352208 -3.0747113  2.2287536 -0.6276562 -2.0871685\n",
      "  2.7496235 -0.1081185 -1.6965067  3.4321244 -1.2172776 -3.1097293\n",
      "  2.0906534 -2.4634714  3.2612672 -0.4141587]\n"
     ]
    }
   ],
   "source": [
    "# # Cargar embeddings\n",
    "# embeddings = np.load(\"node_embeddings.npy\")\n",
    "# print(\"[SHAPE]\",embeddings.shape)\n",
    "# print(\"[EMBEDDING]\",embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosas a tener consideraciom:\n",
    "- GNN al crear un grafo, crea tdoos los nodos que se encuentran en el rango entregado. De esta forma pueden quedar nodos aislados, sin embargo ento causa que no se puedan ir 'actualizando' pero al agregar self_loop se actualizan con si mismos y supondremos que con ello algun patron para este tipo de nodos.\n",
    "- La entrega de embeddings finales esta en orden el ASN de valor inferios hasta el ASN de valor maximo.\n",
    "- Lo guardamso en un .csv dondde se asocia 'node_id' con su embeddings y donde node_id es el ASN del Sistema Autonomo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2114, 0.0000],\n",
       "        [0.2993, 0.2341],\n",
       "        [0.2607, 0.0000],\n",
       "        ...,\n",
       "        [0.1117, 0.0000],\n",
       "        [0.1117, 0.0000],\n",
       "        [0.1117, 0.0000]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gnn.train_g.ndata['feat'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepWalk (2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepWalk como en otros metodos de NLP donde la frecuencia de palabras tiene un comportamiento aque siguie una distribución de ley de potencia (Power Law Distribution). (Pocas palabras tienen una alta aparicion mientras que la mayoria raramente aparece).\n",
    "Este siguie un comportamiento similarar, donde en caminatas aleatorias son pocos los nodos que aparecen frecuentemente, mientras que la mayoria no.\n",
    "\n",
    "* Se apoyan en el mismo concepto que plantea word2vec\n",
    "* De igual manera que word2vec busca estimar la probabilidad de ocurrencia de una palabra en una frase, dadas las palabras cercanas\n",
    "\n",
    "Algoritmo:\n",
    "\n",
    "* DeepWalk genera caminos aleatorios recorriendo el grafo múltiples veces desde todos los nodos con una longitud determinada.\n",
    "* Deep Walk se les llama caminos aleatorios de primer orden ya que se basan en probabilidades de transición de nodo-a-nodo;\n",
    "\n",
    "\n",
    "Resultados esperados:\n",
    "* Bajo la homophily hypothesis, nodos muy conectados entre sí y que pertenecen a las mismas comunidades en el grafo, deben producir embeddings cercanos. \n",
    "* Bajo la structural hypothesis, nodos cuya función estructural en el grafo es similar (por ejemplo, nodos que actúan como hub) también deben producir embeddings cercanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepWalk es un algoritmo para aprender embeddings de nodos en un grafo.\n",
    "¿Cómo funciona?\n",
    "\n",
    "    Hace caminatas aleatorias (random walks) por el grafo, partiendo de cada nodo, como si fueran frases.\n",
    "\n",
    "    Cada caminata es una secuencia de nodos, como una frase es una secuencia de palabras.\n",
    "\n",
    "    Usa Word2Vec (Skip-gram) para aprender embeddings de nodos, tratándolos como si fueran palabras.\n",
    "\n",
    "        Nodo = palabra\n",
    "\n",
    "        Caminata = frase\n",
    "\n",
    "        Grafo = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import DeepWalk\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SparseAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data into cached files.\n",
      "Graph(num_nodes=36173, num_edges=320242,\n",
      "      ndata_schemes={'feat': Scheme(shape=(2,), dtype=torch.float32)}\n",
      "      edata_schemes={'Relationship': Scheme(shape=(), dtype=torch.float32)})\n",
      "[ATTR SHAPE]:  torch.Size([36173, 2])\n",
      "Generando 320242 aristas negativas...\n",
      "Aristas negativas generadas: 320241\n"
     ]
    }
   ],
   "source": [
    "gnn = GNN(debug=True)\n",
    "gnn.load_dataset(dataset_graph_path, force_reload=True)\n",
    "\n",
    "# FIXME: Cambiar, por mientras se estan agregando feat aleatorias o 1s a los nodos\n",
    "# gnn.dgl_graph.ndata['feat'] = torch.ones(gnn.dgl_graph.num_nodes(), 128)            # features de tamano 128\n",
    "\n",
    "print('[ATTR SHAPE]: ',gnn.dgl_graph.ndata['feat'].shape)\n",
    "\n",
    "gnn.split_graph(train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = DeepWalk(gnn.dgl_graph,\n",
    "               emb_dim=32,        # tamaño del embedding\n",
    "               walk_length=6,     # número de saltos por walk\n",
    "                    # tamaño de la ventana de contexto\n",
    "            #    walks_per_node=10,  # número de walks por nodo\n",
    "            #    num_negative=5\n",
    "            # número de negativos por positivo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_walk max: 35760\n",
      "embedding size: 36173\n",
      "[BATCH] torch.Size([128, 40])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding size:\u001b[39m\u001b[38;5;124m\"\u001b[39m, emb\u001b[38;5;241m.\u001b[39mnode_embed\u001b[38;5;241m.\u001b[39mnum_embeddings)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[BATCH]\u001b[39m\u001b[38;5;124m\"\u001b[39m,batch_walk\u001b[38;5;241m.\u001b[39mshape )\n\u001b[0;32m---> 17\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43memb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_walk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/dgl/nn/pytorch/network_emb.py:181\u001b[0m, in \u001b[0;36mDeepWalk.forward\u001b[0;34m(self, batch_walk)\u001b[0m\n\u001b[1;32m    178\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_walk)\n\u001b[1;32m    179\u001b[0m device \u001b[38;5;241m=\u001b[39m batch_walk\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 181\u001b[0m batch_node_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_walk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_dim)\n\u001b[1;32m    182\u001b[0m batch_context_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_embed(batch_walk)\u001b[38;5;241m.\u001b[39mview(\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_dim\n\u001b[1;32m    184\u001b[0m )\n\u001b[1;32m    186\u001b[0m batch_idx_list_offset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(batch_size) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwalk_length\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "emb = DeepWalk(gnn.dgl_graph)\n",
    "dataloader = DataLoader(torch.arange(gnn.dgl_graph.num_nodes()), \n",
    "                        batch_size=128,\n",
    "                        shuffle=True, \n",
    "                        collate_fn=emb.sample)\n",
    "\n",
    "optimizer = SparseAdam(emb.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_walk in dataloader:\n",
    "        print(\"batch_walk max:\", batch_walk.max().item())\n",
    "        print(\"embedding size:\", emb.node_embed.num_embeddings)\n",
    "\n",
    "        print(\"[BATCH]\",batch_walk.shape )\n",
    "        loss = emb(batch_walk)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_walk \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# print(\"[BATCH]\",batch_walk )\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43memb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_walk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     15\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/dgl/nn/pytorch/network_emb.py:181\u001b[0m, in \u001b[0;36mDeepWalk.forward\u001b[0;34m(self, batch_walk)\u001b[0m\n\u001b[1;32m    178\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_walk)\n\u001b[1;32m    179\u001b[0m device \u001b[38;5;241m=\u001b[39m batch_walk\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 181\u001b[0m batch_node_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_walk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_dim)\n\u001b[1;32m    182\u001b[0m batch_context_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_embed(batch_walk)\u001b[38;5;241m.\u001b[39mview(\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_dim\n\u001b[1;32m    184\u001b[0m )\n\u001b[1;32m    186\u001b[0m batch_idx_list_offset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(batch_size) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwalk_length\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "\n",
    "dataloader = DataLoader(torch.arange(gnn.dgl_graph.num_nodes()),\n",
    "                        batch_size=500,\n",
    "                        shuffle=True, \n",
    "                        collate_fn=emb.sample,)\n",
    "\n",
    "optimizer = SparseAdam(emb.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_walk in dataloader:\n",
    "        # print(\"[BATCH]\",batch_walk )\n",
    "        loss = emb(batch_walk)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch_walk in dataloader:\n",
    "#         # Reemplazar -1 por un nodo válido (ej: nodo 0)\n",
    "#         batch_walk[batch_walk == -1] = 0\n",
    "\n",
    "#         loss = emb(batch_walk)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE torch.Size([36173, 32])\n",
      "EMBEDDINGS tensor([[ 0.1550, -0.3473,  0.4126,  ...,  0.3885,  0.3698,  0.2183],\n",
      "        [ 0.2898, -0.3493,  0.3488,  ...,  0.3034,  0.3284,  0.3131],\n",
      "        [ 0.3237, -0.3049,  0.3346,  ...,  0.3572,  0.3408,  0.3349],\n",
      "        ...,\n",
      "        [ 0.0934, -0.1191,  0.1167,  ...,  0.1023,  0.0657,  0.1067],\n",
      "        [ 0.0699, -0.0926,  0.1158,  ...,  0.1232,  0.0960,  0.0738],\n",
      "        [ 0.1134, -0.1234,  0.1093,  ...,  0.0711,  0.0880,  0.0889]])\n"
     ]
    }
   ],
   "source": [
    "h = emb.node_embed.weight.detach()\n",
    "print(\"SHAPE\",h.shape)\n",
    "print(\"EMBEDDINGS\",h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los embeddings\n",
    "torch.save(h, \"data/embeddings.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node2Vec (2016)\n",
    "\n",
    "* Surge con el fin de generalizar DeepWalk.\n",
    "* Node2Vec emplea caminos aleatorios de segundo orden, pues se basa en probabilidades de transición de nodo-a-nodo-a-nodo (o vértice-a-vértice). Es decir, avanzar hacia un nodo determinado no viene sólo dado por el nodo en el que nos encontremos, sino también por el nodo anterior de donde vengamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se apoyan en el mismo concepto que plantea word2vec\n",
    "* De igual manera que word2vec busca estimar la probabilidad de ocurrencia de una palabra en una frase, dadas las palabras cercanas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node2Vec es una mejora de DeepWalk. También genera caminatas y usa Word2Vec, pero:\n",
    "    Introduce dos parámetros:\n",
    "        pp: controla la probabilidad de volver atrás (tipo DFS).\n",
    "\n",
    "        qq: controla la probabilidad de explorar localmente (tipo BFS).\n",
    "\n",
    "    Así, Node2Vec puede balancear entre exploración profunda (estructural) y local (de vecindad).\n",
    "\n",
    "Esto permite obtener embeddings que capturan diferentes tipos de relaciones:\n",
    "\n",
    "    Parecidos en rol (ej: puentes entre comunidades).\n",
    "\n",
    "    Parecidos en vecindad (ej: miembros de la misma comunidad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
