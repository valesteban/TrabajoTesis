{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Embeddings con GNN\n",
    "Aca crearemos embeddings paa un grafo de Internet, es decir represenaciones de los SA a partir de la topologia y atributos de los SA.\n",
    "\n",
    "Para esto tomamos 3 enfoques:\n",
    "\n",
    "\n",
    "*   [Caso 1] Reconstruction Approach autoencoder: A traves de la prediccion de aristas construimos los embeddings de los nodos.\n",
    "*   [Caso 1.1] Reconstruction Approach autoencoder: en ves de ocupar las bgp routes recolectadas de los ribs ocupamos las relaciones de AS rank y le damso attr a las aristas (es solo para probar que lo estemos ahciendo bien y las cosas tienen sentido)\n",
    "*   [Caso 2]: Reconstruction Approach attribute Masking:\n",
    "*   Caso 3: Task Generation Pre-calculated descriptor\n",
    "\n",
    "Para cada uno crearemos un ejemplo.\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install  dgl -f https://data.dgl.ai/wheels/torch-2.3/cu121/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentina/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from modules.gnn import GNN\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from modules.graph import Graph, create_files\n",
    "from modules.gnn import GNN\n",
    "from modules.gnn_models import GCN, GraphSAGE, GAT\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las rutas de los archivos\n",
    "BASE_PATH = os.getcwd() + \"/data/\"\n",
    "RELATIONSHIPS_FILE  = BASE_PATH + \"CAIDA_AS_Relationships/Serial_1/20220701.as-rel.txt.bz2\"\n",
    "FEATURES_FILE = BASE_PATH + \"/node_feature_mio.csv\" #\"/node_features.csv\" \n",
    "rib_path = BASE_PATH + 'sanitized_rib.txt'\n",
    "dataset_graph_path = BASE_PATH + 'dgl_graph/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion Grafo \n",
    "Creamos un grafo nx y dgl, ademas de los archivos edges.csv y nodes.csv a partir de archivos ribs previamente creados o de archivo CAIDA AS Relationships.\n",
    "\n",
    "Crear esos archivos una unica vez con create_graph() una ves ya creados los archivos edges.csv y nodes.csv puedo ocupar directamente la funcion \n",
    "\n",
    "Se le puede indicar el maximo de bgp paths que se quiere (hehco para cuando se leen ribs no de caida) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASO 1: RIBs\n",
    "* Creacion de grafo a partir de paths recolectados de las RIBs por BGPStream\n",
    "* Por ahora le asignamos a todos los nodos embeddings iniciales de de dimension 32 parte con puros 1s todos\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
=======
   "execution_count": 9,
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaRPETA CREADA]:  /home/valentina/Desktop/GIT/TrabajoTesis/data/dgl_graph/\n",
      "[Creando topologia]\n",
      "[ARCHIVO EDGES.CSV CREADO]\n",
<<<<<<< HEAD
      "[NX Graph]:  MultiDiGraph with 10299 nodes and 33437 edges\n",
      "[Agregando attr]\n",
      "[NX Graph]:  MultiDiGraph with 10299 nodes and 33437 edges\n",
      "nodes.csv edges.csv\n",
      "[FEATURES CREADOS]\n",
=======
      "[NX Graph]:  MultiDiGraph with 36173 nodes and 330327 edges\n",
      "[TOPOLOGIA CREADA]\n",
      "[ARCHIVO NODES.CSV CREADO], 180 nodos sin features\n",
      "[NX Graph]:  MultiDiGraph with 36173 nodes and 330327 edges\n",
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
      "[META CREADO]\n",
      "[NX Graph]:  MultiDiGraph with 3731 nodes and 26869 edges\n",
      "[NX Graph]:  MultiDiGraph with 3034 nodes and 26172 edges\n",
      "[NX Graph]:  MultiDiGraph with 2989 nodes and 26127 edges\n",
      "[NX Graph] MultiDiGraph with 2989 nodes and 26127 edges\n"
     ]
    }
   ],
   "source": [
    "\n",
<<<<<<< HEAD
    "# features_file = 'node_degrees' #'' # 'node_degrees' # las features que se le agregaran seran \n",
    "# features_file = base_path + \"/node_features.csv\"\n",
    "features_file = base_path + \"/node_features_mio.csv\"\n",
    "type = 'MultiDiGraph'#\"DiGraph\" # MultiDiGraph\n",
    "relationships_file\n",
    "MAX_NUM_ROUTES = 1000000\n",
=======
    "FEATURES_FILE = FEATURES_FILE#'node_degrees' #'' # 'node_degrees' # las features que se le agregaran seran \n",
    "type = 'MultiDiGraph'#\"DiGraph\" # MultiDiGraph\n",
    "MAX_PATHS = 100000\n",
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
    "graph_case1 = create_files(type, \n",
    "            dataset_graph_path,\n",
    "            file = rib_path, \n",
    "            features_file = FEATURES_FILE, \n",
    "            from_caida=False, \n",
    "            remove_degree=3,\n",
    "            debug=True,\n",
    "            max_paths = MAX_PATHS)\n",
    " \n",
    "print('[NX Graph]',graph_case1.nx_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASO 2: CAIDA Relationships\n",
    "* Creacion del grafo a partir de CAIDA AS Relationships (AS Rank) \n",
    "* Se les da atributos a los edges correspondientes al tipo de relacion que comparten\n",
    "* Es solo de prueba "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 51,
=======
   "execution_count": 8,
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[CaRPETA CREADA]:  /home/valentina/Desktop/GIT/TrabajoTesis/data/dgl_graph/\n",
      "[NX Graph]:  DiGraph with 74140 nodes and 379420 edges\n",
      "[TOPOLOGIA CREADA]\n",
      "[todos attr]\n",
      "[bbbbbbbbbbbbbbbbbbbbbb]\n",
      "[NX Graph]:  DiGraph with 74140 nodes and 379420 edges\n",
      "nodes.csv edges.csv\n",
      "[FEATURES CREADOS]\n",
      "[META CREADO]\n",
      "[NX Graph]:  DiGraph with 46714 nodes and 351994 edges\n",
      "[NX Graph]:  DiGraph with 46237 nodes and 351517 edges\n",
      "[NX Graph]:  DiGraph with 46229 nodes and 351509 edges\n",
      "[NX Graph] DiGraph with 46229 nodes and 351509 edges\n"
=======
      "[CaRPETA CREADA]:  /home/valentina/Desktop/GIT/TrabajoTesis/data/dgl_graph/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m TYPE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiGraph\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# MultiDiGraph\u001b[39;00m\n\u001b[1;32m      4\u001b[0m MAX_PATHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100000\u001b[39m\n\u001b[0;32m----> 5\u001b[0m graph_case1 \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdataset_graph_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m             \u001b[49m\u001b[43mRELATIONSHIPS_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m             \u001b[49m\u001b[43mFEATURES_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m             \u001b[49m\u001b[43mfrom_caida\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m             \u001b[49m\u001b[43mremove_degree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43mmax_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[NX Graph]\u001b[39m\u001b[38;5;124m'\u001b[39m,graph_case1\u001b[38;5;241m.\u001b[39mnx_graph)\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/modules/graph.py:363\u001b[0m, in \u001b[0;36mcreate_files\u001b[0;34m(graph_type, dataset_graph_path, file, features_file, from_caida, feature_list, remove_degree, debug, max_paths)\u001b[0m\n\u001b[1;32m    360\u001b[0m graph \u001b[38;5;241m=\u001b[39m Graph(dataset_graph_path, max_paths ,debug\u001b[38;5;241m=\u001b[39mdebug)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_caida \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m     \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_graph_from_caida\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m     graph\u001b[38;5;241m.\u001b[39mcreate_topology_from_ribs(rib_filename\u001b[38;5;241m=\u001b[39mfile, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mgraph_type)\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/modules/graph.py:96\u001b[0m, in \u001b[0;36mGraph.create_graph_from_caida\u001b[0;34m(self, filename, type, filename_out)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Creamos DataFrame\u001b[39;00m\n\u001b[1;32m     95\u001b[0m df_edges \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(tor_dataset, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdst_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 96\u001b[0m \u001b[43mdf_edges\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRelationship\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m labels\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Creamoss archivo edges.csv\u001b[39;00m\n\u001b[1;32m     99\u001b[0m df_edges\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medges.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/pandas/core/frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/pandas/core/frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4517\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4530\u001b[0m     ):\n\u001b[1;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/pandas/core/frame.py:5267\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m   5266\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m-> 5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n\u001b[1;32m   5275\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   5276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting an Index with object dtype into a DataFrame will stop \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5277\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferring another dtype in a future version. Cast the Index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5280\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   5281\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/pandas/core/construction.py:654\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    651\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m _try_cast(data, dtype, copy)\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 654\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_platform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subarr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    656\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:138\u001b[0m, in \u001b[0;36mmaybe_convert_platform\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m _dtype_obj:\n\u001b[1;32m    137\u001b[0m     arr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, arr)\n\u001b[0;32m--> 138\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# Definimos las listas de features\n",
    "\n",
    "features_file =  'data/node_features.csv'  #'node_degrees' #'' # 'node_degrees' # las features que se le agregaran seran \n",
    "type = \"DiGraph\" # MultiDiGraph\n",
    "\n",
    "max_paths = 100000\n",
    "graph_case1 = create_files(type, \n",
=======
    "\n",
    "FEATURES_FILE =  'data/node_features.csv'  #'node_degrees' #'' # 'node_degrees' # las features que se le agregaran seran \n",
    "TYPE = \"DiGraph\" # MultiDiGraph\n",
    "\n",
    "MAX_PATHS = 100000\n",
    "graph_case1 = create_files(TYPE, \n",
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
    "             dataset_graph_path,\n",
    "             RELATIONSHIPS_FILE, \n",
    "             FEATURES_FILE, \n",
    "             from_caida=True, \n",
    "             remove_degree=3,\n",
    "             debug=True,\n",
    "max_paths = None)\n",
    " \n",
    "print('[NX Graph]',graph_case1.nx_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Prediction: Encode-Decoder "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
=======
   "execution_count": 10,
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import CoraGraphDataset\n",
    "from dgl.dataloading import negative_sampler\n",
    "import dgl.function as fn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from dgl.nn import SAGEConv, GraphConv, GATConv, GINConv, GatedGCNConv, GatedGraphConv\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "from dgl.nn import SAGEConv\n",
    "from dgl.nn import SAGEConv, GraphConv, GATConv, GINConv, GatedGCNConv, GatedGraphConv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
=======
   "execution_count": 11,
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(pos_score,neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    )\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASO 1: \n",
    "* Encoder : GNN -> (GCN , GraphSAGE, GAT)\n",
    "* Decoder : DotProduct"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'GCN': GCN,\n",
    "    'GraphSAGE': GraphSAGE,\n",
    "    'GAT': GAT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
=======
   "execution_count": 12,
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data into cached files.\n",
<<<<<<< HEAD
      "Graph(num_nodes=10299, num_edges=26127,\n",
      "      ndata_schemes={'feat': Scheme(shape=(69,), dtype=torch.float32)}\n",
      "      edata_schemes={'Relationship': Scheme(shape=(), dtype=torch.float32)})\n",
      "[ATTR SHAPE]:  torch.Size([10299, 69])\n",
      "Generando 26127 aristas negativas...\n",
      "Aristas negativas generadas: 26126\n"
=======
      "Graph(num_nodes=36173, num_edges=320242,\n",
      "      ndata_schemes={'feat': Scheme(shape=(72,), dtype=torch.float32)}\n",
      "      edata_schemes={'Relationship': Scheme(shape=(), dtype=torch.float32)})\n",
      "[ATTR SHAPE]:  torch.Size([36173, 72])\n",
      "Generando 320242 aristas negativas...\n",
      "Aristas negativas generadas: 320241\n"
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
     ]
    }
   ],
   "source": [
    "gnn = GNN(debug=True)\n",
    "gnn.load_dataset(dataset_graph_path, force_reload=True)\n",
    "\n",
    "print('[ATTR SHAPE]: ',gnn.dgl_graph.ndata['feat'].shape)\n",
    "in_feats = gnn.dgl_graph.ndata['feat'].shape[1]\n",
    "gnn.split_graph_edges(train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": 13,
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Training model: GCN\n",
      "In epoch 0, loss: 0.5790210962295532\n",
      "In epoch 5, loss: 0.4952738881111145\n",
      "In epoch 10, loss: 0.47094234824180603\n",
      "In epoch 15, loss: 0.45358189940452576\n",
      "In epoch 20, loss: 0.4365786612033844\n",
      "In epoch 25, loss: 0.42139825224876404\n",
      "In epoch 30, loss: 0.4087642729282379\n",
      "In epoch 35, loss: 0.39747247099876404\n",
      "In epoch 40, loss: 0.38712453842163086\n",
      "In epoch 45, loss: 0.3779893219470978\n",
      "AUC 0.8976797923284744\n",
      "Training model: GraphSAGE\n",
      "In epoch 0, loss: 0.8710216879844666\n",
      "In epoch 5, loss: 0.47554782032966614\n",
      "In epoch 10, loss: 0.42777785658836365\n",
      "In epoch 15, loss: 0.4056820273399353\n",
      "In epoch 20, loss: 0.389257550239563\n",
      "In epoch 25, loss: 0.3758694529533386\n",
      "In epoch 30, loss: 0.36489546298980713\n",
      "In epoch 35, loss: 0.3565472960472107\n",
      "In epoch 40, loss: 0.34861689805984497\n",
      "In epoch 45, loss: 0.3418048918247223\n",
      "AUC 0.9044755706523914\n",
      "Training model: GAT\n",
      "In epoch 0, loss: 0.7432406544685364\n",
      "In epoch 5, loss: 0.5007410049438477\n",
      "In epoch 10, loss: 0.45538488030433655\n",
      "In epoch 15, loss: 0.43936726450920105\n",
      "In epoch 20, loss: 0.4256216287612915\n",
      "In epoch 25, loss: 0.41701778769493103\n",
      "In epoch 30, loss: 0.4103829562664032\n",
      "In epoch 35, loss: 0.4034545421600342\n",
      "In epoch 40, loss: 0.3978373408317566\n",
      "In epoch 45, loss: 0.39293456077575684\n",
      "AUC 0.8960065212138155\n"
=======
      "In epoch 0, loss: 22.05376434326172\n",
      "In epoch 5, loss: 1.5552303791046143\n",
      "In epoch 10, loss: 0.8545680046081543\n",
      "In epoch 15, loss: 0.6652436256408691\n",
      "In epoch 20, loss: 0.6501172184944153\n",
      "In epoch 25, loss: 0.6128706336021423\n",
      "In epoch 30, loss: 0.5987074971199036\n",
      "In epoch 35, loss: 0.5776962041854858\n",
      "In epoch 40, loss: 0.5544006824493408\n",
      "In epoch 45, loss: 0.5384299755096436\n",
      "In epoch 50, loss: 0.5244908332824707\n",
      "In epoch 55, loss: 0.5118464231491089\n",
      "In epoch 60, loss: 0.5013339519500732\n",
      "In epoch 65, loss: 0.49244144558906555\n",
      "In epoch 70, loss: 0.48425090312957764\n",
      "In epoch 75, loss: 0.47684577107429504\n",
      "In epoch 80, loss: 0.4704488515853882\n",
      "In epoch 85, loss: 0.4649095833301544\n",
      "In epoch 90, loss: 0.4598625898361206\n",
      "In epoch 95, loss: 0.45539623498916626\n",
      "AUC 0.9256399802945692\n"
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
     ]
    }
   ],
   "source": [
    "decorer = 'DotProduct'\n",
    "in_feats = gnn.dgl_graph.ndata['feat'].shape[1]\n",
    "hidden_feats = 32 \n",
    "out_feats = 16\n",
    "\n",
    "for model_name in models:\n",
    "\n",
    "    print(\"Training model: {}\".format(model_name))\n",
    "\n",
    "    model = models[model_name](\n",
    "        in_feats=in_feats,\n",
    "        hidden_feats=hidden_feats,\n",
    "        out_feats=out_feats)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # ----------- training -------------------------------- #\n",
    "\n",
    "    all_logits = []\n",
    "    for e in range(50):\n",
    "\n",
    "        # forward\n",
    "        model.train()\n",
    "        h = model.encode(gnn.train_g, gnn.train_g.ndata[\"feat\"])\n",
    "\n",
    "        pos_score = model.decodeDotProduct(gnn.train_pos_g, h)\n",
    "        neg_score = model.decodeDotProduct(gnn.train_neg_g, h)\n",
    "\n",
    "\n",
    "        loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print(\"In epoch {}, loss: {}\".format(e, loss))\n",
    "\n",
    "    # ----------- 5. check results ------------------------ #\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pos_score = model.decodeDotProduct(gnn.test_pos_g, h)\n",
    "        neg_score = model.decodeDotProduct(gnn.test_neg_g, h)\n",
    "        print(\"AUC\", compute_auc(pos_score, neg_score))\n",
    "    \n",
    "    # Guaradar el modelo\n",
    "    torch.save(model.state_dict(), f'data/model_emb_{model_name}.pth')\n",
    "\n",
    "    # Guardar los embeddings\n",
    "    torch.save(h, f\"data/embeddings_ribs_DP_{model_name}.pt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO] GraphSAGE(\n",
      "  (conv1): SAGEConv(\n",
      "    (feat_drop): Dropout(p=0.0, inplace=False)\n",
      "    (fc_neigh): Linear(in_features=72, out_features=16, bias=False)\n",
      "    (fc_self): Linear(in_features=72, out_features=16, bias=True)\n",
      "  )\n",
      "  (conv2): SAGEConv(\n",
      "    (feat_drop): Dropout(p=0.0, inplace=False)\n",
      "    (fc_neigh): Linear(in_features=16, out_features=16, bias=False)\n",
      "    (fc_self): Linear(in_features=16, out_features=16, bias=True)\n",
      "  )\n",
      "  (decoder): MLPPredictor(\n",
      "    (W1): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (W2): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ") \n",
      "[EMBEDDINGS] tensor([[-0.0205,  0.0084,  0.0781,  ..., -0.0022, -0.1683,  0.1649],\n",
      "        [-0.1358,  0.1089, -0.0164,  ..., -0.0270, -0.1291,  0.1019],\n",
      "        [-0.1593,  0.2170, -0.0731,  ..., -0.0072,  0.0196, -0.0310],\n",
      "        ...,\n",
      "        [-0.1095,  0.1270, -0.0356,  ..., -0.0195, -0.0160,  0.0089],\n",
      "        [-0.0686,  0.0427,  0.0153,  ..., -0.0200, -0.0592,  0.0413],\n",
      "        [-0.2212,  0.3570, -0.1748,  ..., -0.0181,  0.1019, -0.0798]],\n",
      "       grad_fn=<AddBackward0>) \n"
     ]
    }
   ],
   "source": [
    "print(f'[MODELO] {model} ')\n",
    "print(f'[EMBEDDINGS] {h} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo y embeddings \n",
    "# Guaradar el modelo\n",
    "torch.save(model.state_dict(), f'data/model_emb.pth')\n",
    "\n",
    "# Guardar los embeddings\n",
    "torch.save(h, f\"data/embeddings.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASO 2: \n",
    "* Encoder : GNN\n",
    "* Decoder : MLP"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 16,
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data into cached files.\n",
<<<<<<< HEAD
      "Graph(num_nodes=10299, num_edges=26127,\n",
      "      ndata_schemes={'feat': Scheme(shape=(69,), dtype=torch.float32)}\n",
      "      edata_schemes={'Relationship': Scheme(shape=(), dtype=torch.float32)})\n",
      "[ATTR SHAPE]:  torch.Size([10299, 69])\n",
      "Generando 26127 aristas negativas...\n",
      "Aristas negativas generadas: 26126\n"
=======
      "Graph(num_nodes=36173, num_edges=320242,\n",
      "      ndata_schemes={'feat': Scheme(shape=(72,), dtype=torch.float32)}\n",
      "      edata_schemes={'Relationship': Scheme(shape=(), dtype=torch.float32)})\n",
      "[ATTR SHAPE]:  torch.Size([36173, 72])\n",
      "Generando 320242 aristas negativas...\n",
      "Aristas negativas generadas: 320241\n"
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
     ]
    }
   ],
   "source": [
    "gnn = GNN(debug=True)\n",
    "gnn.load_dataset(dataset_graph_path, force_reload=True)\n",
    "\n",
    "print('[ATTR SHAPE]: ',gnn.dgl_graph.ndata['feat'].shape)\n",
    "\n",
    "gnn.split_graph_edges(train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 17,
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Training model: GCN\n",
      "In epoch 0, loss: 0.6961654424667358\n",
      "In epoch 5, loss: 0.5532019138336182\n",
      "In epoch 10, loss: 0.4814865291118622\n",
      "In epoch 15, loss: 0.38714584708213806\n",
      "In epoch 20, loss: 0.293878972530365\n",
      "In epoch 25, loss: 0.2664203345775604\n",
      "In epoch 30, loss: 0.22582508623600006\n",
      "In epoch 35, loss: 0.2041793167591095\n",
      "In epoch 40, loss: 0.18517975509166718\n",
      "In epoch 45, loss: 0.1648598164319992\n",
      "AUC 0.9574349265415985\n",
      "Training model: GraphSAGE\n",
      "In epoch 0, loss: 0.7757411599159241\n",
      "In epoch 5, loss: 0.4722431004047394\n",
      "In epoch 10, loss: 0.3182899057865143\n",
      "In epoch 15, loss: 0.2028316855430603\n",
      "In epoch 20, loss: 0.14605417847633362\n",
      "In epoch 25, loss: 0.11154832690954208\n",
      "In epoch 30, loss: 0.0927392765879631\n",
      "In epoch 35, loss: 0.07833690196275711\n",
      "In epoch 40, loss: 0.06895168125629425\n",
      "In epoch 45, loss: 0.0612853541970253\n",
      "AUC 0.9546512880234183\n",
      "Training model: GAT\n",
      "In epoch 0, loss: 0.6819234490394592\n",
      "In epoch 5, loss: 0.5034317374229431\n",
      "In epoch 10, loss: 0.33427879214286804\n",
      "In epoch 15, loss: 0.23913191258907318\n",
      "In epoch 20, loss: 0.18748094141483307\n",
      "In epoch 25, loss: 0.1588706225156784\n",
      "In epoch 30, loss: 0.1464986503124237\n",
      "In epoch 35, loss: 0.14223934710025787\n",
      "In epoch 40, loss: 0.13617801666259766\n",
      "In epoch 45, loss: 0.13212363421916962\n",
      "AUC 0.8928110313547728\n"
=======
      "In epoch 0, loss: 0.6860744953155518\n",
      "In epoch 5, loss: 0.444807767868042\n",
      "In epoch 10, loss: 0.24612581729888916\n",
      "In epoch 15, loss: 0.1682116538286209\n",
      "In epoch 20, loss: 0.12941059470176697\n",
      "In epoch 25, loss: 0.10903869569301605\n",
      "In epoch 30, loss: 0.09894604980945587\n",
      "In epoch 35, loss: 0.09444298595190048\n",
      "In epoch 40, loss: 0.09098073840141296\n",
      "In epoch 45, loss: 0.08767183870077133\n",
      "In epoch 50, loss: 0.0846048966050148\n",
      "In epoch 55, loss: 0.08212506771087646\n",
      "In epoch 60, loss: 0.07962386310100555\n",
      "In epoch 65, loss: 0.07835791260004044\n",
      "In epoch 70, loss: 0.07584322988986969\n",
      "In epoch 75, loss: 0.07455567270517349\n",
      "In epoch 80, loss: 0.07379470020532608\n",
      "In epoch 85, loss: 0.07209838181734085\n",
      "In epoch 90, loss: 0.07249067723751068\n",
      "In epoch 95, loss: 0.07056012749671936\n",
      "AUC 0.9907695964029664\n"
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
     ]
    }
   ],
   "source": [
    "\n",
    "in_feats = gnn.dgl_graph.ndata['feat'].shape[1]\n",
    "hidden_feats = 32 \n",
    "out_feats = 16\n",
    "\n",
    "for model_name in models:\n",
    "\n",
    "    print(\"Training model: {}\".format(model_name))\n",
    "\n",
    "    model = models[model_name](\n",
    "        in_feats=in_feats,\n",
    "        hidden_feats=hidden_feats,\n",
    "        out_feats=out_feats )\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # ----------- training -------------------------------- #\n",
    "\n",
    "    all_logits = []\n",
    "    for e in range(50):\n",
    "\n",
    "        # forward\n",
    "        model.train()\n",
    "        h = model.encode(gnn.train_g, gnn.train_g.ndata[\"feat\"])\n",
    "\n",
    "        pos_score = model.decodeMLP(gnn.train_pos_g, h)\n",
    "        neg_score = model.decodeMLP(gnn.train_neg_g, h)\n",
    "\n",
    "\n",
    "        loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print(\"In epoch {}, loss: {}\".format(e, loss))\n",
    "\n",
    "    # ----------- check results ------------------------ #\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pos_score = model.decodeMLP(gnn.test_pos_g, h)\n",
    "        neg_score = model.decodeMLP(gnn.test_neg_g, h)\n",
    "        print(\"AUC\", compute_auc(pos_score, neg_score))\n",
    "\n",
    "    # Guaradar el modelo\n",
    "    torch.save(model.state_dict(), f'data/model_emb_{model_name}.pth')\n",
    "\n",
    "    # Guardar los embeddings\n",
    "    torch.save(h, f\"data/embeddings_ribs_MLP_{model_name}.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 18,
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "conv1.fc_neigh.weight torch.Size([16, 69])\n",
      "conv1.fc_self.weight torch.Size([16, 69])\n",
=======
      "conv1.fc_neigh.weight torch.Size([16, 72])\n",
      "conv1.fc_self.weight torch.Size([16, 72])\n",
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
      "conv1.fc_self.bias torch.Size([16])\n",
      "conv2.fc_neigh.weight torch.Size([16, 16])\n",
      "conv2.fc_self.weight torch.Size([16, 16])\n",
      "conv2.fc_self.bias torch.Size([16])\n",
      "decoder.W1.weight torch.Size([16, 32])\n",
      "decoder.W1.bias torch.Size([16])\n",
      "decoder.W2.weight torch.Size([1, 16])\n",
      "decoder.W2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Se incluyen los parametros tanto de MLP como de la GNN\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
=======
    "#### Guardar Modelo y Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guaradar el modelo\n",
    "torch.save(model.state_dict(), 'data/model_emb.pth')\n",
    "\n",
    "# Guardar los embeddings\n",
    "torch.save(h, \"data/embeddings.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings guardados en 'node_embeddings.csv'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.101930</td>\n",
       "      <td>-0.335221</td>\n",
       "      <td>-3.074711</td>\n",
       "      <td>2.228754</td>\n",
       "      <td>-0.627656</td>\n",
       "      <td>-2.087168</td>\n",
       "      <td>2.749624</td>\n",
       "      <td>-0.108119</td>\n",
       "      <td>-1.696507</td>\n",
       "      <td>3.432124</td>\n",
       "      <td>-1.217278</td>\n",
       "      <td>-3.109729</td>\n",
       "      <td>2.090653</td>\n",
       "      <td>-2.463471</td>\n",
       "      <td>3.261267</td>\n",
       "      <td>-0.414159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.723648</td>\n",
       "      <td>-1.042069</td>\n",
       "      <td>-2.855011</td>\n",
       "      <td>1.761993</td>\n",
       "      <td>-0.334552</td>\n",
       "      <td>-1.730516</td>\n",
       "      <td>3.329224</td>\n",
       "      <td>-0.171126</td>\n",
       "      <td>-2.141119</td>\n",
       "      <td>3.345304</td>\n",
       "      <td>-0.868315</td>\n",
       "      <td>-3.146378</td>\n",
       "      <td>2.222488</td>\n",
       "      <td>-2.328668</td>\n",
       "      <td>3.026546</td>\n",
       "      <td>-0.028456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.158578</td>\n",
       "      <td>-1.128411</td>\n",
       "      <td>-3.201206</td>\n",
       "      <td>2.089556</td>\n",
       "      <td>-0.243688</td>\n",
       "      <td>-2.558243</td>\n",
       "      <td>3.160474</td>\n",
       "      <td>1.796038</td>\n",
       "      <td>-1.859045</td>\n",
       "      <td>2.827035</td>\n",
       "      <td>-1.029408</td>\n",
       "      <td>-3.751191</td>\n",
       "      <td>1.974931</td>\n",
       "      <td>-3.294911</td>\n",
       "      <td>3.833996</td>\n",
       "      <td>-0.531082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.077238</td>\n",
       "      <td>-0.910498</td>\n",
       "      <td>-3.221866</td>\n",
       "      <td>2.284746</td>\n",
       "      <td>-0.425296</td>\n",
       "      <td>-2.518895</td>\n",
       "      <td>3.067572</td>\n",
       "      <td>1.671393</td>\n",
       "      <td>-1.717550</td>\n",
       "      <td>2.932030</td>\n",
       "      <td>-1.126791</td>\n",
       "      <td>-3.613750</td>\n",
       "      <td>2.083611</td>\n",
       "      <td>-3.193594</td>\n",
       "      <td>3.809445</td>\n",
       "      <td>-0.619963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.975382</td>\n",
       "      <td>-0.805138</td>\n",
       "      <td>-3.114366</td>\n",
       "      <td>2.234302</td>\n",
       "      <td>-0.293983</td>\n",
       "      <td>-2.377515</td>\n",
       "      <td>2.980376</td>\n",
       "      <td>1.467021</td>\n",
       "      <td>-1.709631</td>\n",
       "      <td>2.908147</td>\n",
       "      <td>-1.105135</td>\n",
       "      <td>-3.563770</td>\n",
       "      <td>2.021119</td>\n",
       "      <td>-3.159290</td>\n",
       "      <td>3.726334</td>\n",
       "      <td>-0.601326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36168</th>\n",
       "      <td>0.860783</td>\n",
       "      <td>-1.317075</td>\n",
       "      <td>-3.237432</td>\n",
       "      <td>2.151350</td>\n",
       "      <td>0.031120</td>\n",
       "      <td>-2.795558</td>\n",
       "      <td>3.234994</td>\n",
       "      <td>3.156262</td>\n",
       "      <td>-1.719627</td>\n",
       "      <td>2.397869</td>\n",
       "      <td>-1.008901</td>\n",
       "      <td>-4.016392</td>\n",
       "      <td>1.883370</td>\n",
       "      <td>-3.971356</td>\n",
       "      <td>4.242860</td>\n",
       "      <td>-0.700788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36169</th>\n",
       "      <td>-0.368163</td>\n",
       "      <td>1.001421</td>\n",
       "      <td>-1.172179</td>\n",
       "      <td>2.207545</td>\n",
       "      <td>-1.146080</td>\n",
       "      <td>-1.596958</td>\n",
       "      <td>0.281243</td>\n",
       "      <td>-0.243500</td>\n",
       "      <td>1.134093</td>\n",
       "      <td>1.264028</td>\n",
       "      <td>-0.823900</td>\n",
       "      <td>-1.051718</td>\n",
       "      <td>-0.904146</td>\n",
       "      <td>-1.968068</td>\n",
       "      <td>1.897566</td>\n",
       "      <td>-1.251757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36170</th>\n",
       "      <td>1.198884</td>\n",
       "      <td>-0.767427</td>\n",
       "      <td>-3.267465</td>\n",
       "      <td>2.391738</td>\n",
       "      <td>-0.707687</td>\n",
       "      <td>-2.478895</td>\n",
       "      <td>3.019535</td>\n",
       "      <td>1.173728</td>\n",
       "      <td>-1.692087</td>\n",
       "      <td>3.166048</td>\n",
       "      <td>-1.204719</td>\n",
       "      <td>-3.448300</td>\n",
       "      <td>2.203176</td>\n",
       "      <td>-2.884263</td>\n",
       "      <td>3.673004</td>\n",
       "      <td>-0.615303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36171</th>\n",
       "      <td>1.001862</td>\n",
       "      <td>-0.510832</td>\n",
       "      <td>-3.042523</td>\n",
       "      <td>2.209620</td>\n",
       "      <td>-0.383830</td>\n",
       "      <td>-2.157973</td>\n",
       "      <td>2.739654</td>\n",
       "      <td>0.726272</td>\n",
       "      <td>-1.620797</td>\n",
       "      <td>3.045597</td>\n",
       "      <td>-1.227402</td>\n",
       "      <td>-3.290534</td>\n",
       "      <td>2.098525</td>\n",
       "      <td>-2.784280</td>\n",
       "      <td>3.451292</td>\n",
       "      <td>-0.502860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36172</th>\n",
       "      <td>0.798523</td>\n",
       "      <td>-1.340431</td>\n",
       "      <td>-3.298937</td>\n",
       "      <td>2.231372</td>\n",
       "      <td>0.045777</td>\n",
       "      <td>-2.871834</td>\n",
       "      <td>3.280957</td>\n",
       "      <td>3.517978</td>\n",
       "      <td>-1.663943</td>\n",
       "      <td>2.330639</td>\n",
       "      <td>-1.024352</td>\n",
       "      <td>-4.090005</td>\n",
       "      <td>1.931069</td>\n",
       "      <td>-4.139738</td>\n",
       "      <td>4.372475</td>\n",
       "      <td>-0.755890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36173 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6   \\\n",
       "node_id                                                                         \n",
       "0        1.101930 -0.335221 -3.074711  2.228754 -0.627656 -2.087168  2.749624   \n",
       "1        1.723648 -1.042069 -2.855011  1.761993 -0.334552 -1.730516  3.329224   \n",
       "2        1.158578 -1.128411 -3.201206  2.089556 -0.243688 -2.558243  3.160474   \n",
       "3        1.077238 -0.910498 -3.221866  2.284746 -0.425296 -2.518895  3.067572   \n",
       "4        0.975382 -0.805138 -3.114366  2.234302 -0.293983 -2.377515  2.980376   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "36168    0.860783 -1.317075 -3.237432  2.151350  0.031120 -2.795558  3.234994   \n",
       "36169   -0.368163  1.001421 -1.172179  2.207545 -1.146080 -1.596958  0.281243   \n",
       "36170    1.198884 -0.767427 -3.267465  2.391738 -0.707687 -2.478895  3.019535   \n",
       "36171    1.001862 -0.510832 -3.042523  2.209620 -0.383830 -2.157973  2.739654   \n",
       "36172    0.798523 -1.340431 -3.298937  2.231372  0.045777 -2.871834  3.280957   \n",
       "\n",
       "               7         8         9         10        11        12        13  \\\n",
       "node_id                                                                         \n",
       "0       -0.108119 -1.696507  3.432124 -1.217278 -3.109729  2.090653 -2.463471   \n",
       "1       -0.171126 -2.141119  3.345304 -0.868315 -3.146378  2.222488 -2.328668   \n",
       "2        1.796038 -1.859045  2.827035 -1.029408 -3.751191  1.974931 -3.294911   \n",
       "3        1.671393 -1.717550  2.932030 -1.126791 -3.613750  2.083611 -3.193594   \n",
       "4        1.467021 -1.709631  2.908147 -1.105135 -3.563770  2.021119 -3.159290   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "36168    3.156262 -1.719627  2.397869 -1.008901 -4.016392  1.883370 -3.971356   \n",
       "36169   -0.243500  1.134093  1.264028 -0.823900 -1.051718 -0.904146 -1.968068   \n",
       "36170    1.173728 -1.692087  3.166048 -1.204719 -3.448300  2.203176 -2.884263   \n",
       "36171    0.726272 -1.620797  3.045597 -1.227402 -3.290534  2.098525 -2.784280   \n",
       "36172    3.517978 -1.663943  2.330639 -1.024352 -4.090005  1.931069 -4.139738   \n",
       "\n",
       "               14        15  \n",
       "node_id                      \n",
       "0        3.261267 -0.414159  \n",
       "1        3.026546 -0.028456  \n",
       "2        3.833996 -0.531082  \n",
       "3        3.809445 -0.619963  \n",
       "4        3.726334 -0.601326  \n",
       "...           ...       ...  \n",
       "36168    4.242860 -0.700788  \n",
       "36169    1.897566 -1.251757  \n",
       "36170    3.673004 -0.615303  \n",
       "36171    3.451292 -0.502860  \n",
       "36172    4.372475 -0.755890  \n",
       "\n",
       "[36173 rows x 16 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Guaradar el modelo\n",
    "# torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# # Guardar los embeddings de los nodos despuÃ©s del entrenamiento\n",
    "# with torch.no_grad():\n",
    "#     # Calcular los embeddings finales\n",
    "#     # final_embeddings = model.encode(train_g, train_g.ndata[\"feat\"]).detach().cpu().numpy()\n",
    "#     final_embeddings = h.detach().cpu().numpy()\n",
    "\n",
    "#     # Crear un DataFrame para guardar los embeddings\n",
    "#     # Obtener ids de los nodos (ASN)\n",
    "#     # node_ids = train_g.nodes().numpy()\n",
    "#     node_ids = gnn.dgl_graph.nodes().numpy()\n",
    "\n",
    "#     emb_df = pd.DataFrame(final_embeddings, index=node_ids)\n",
    "#     emb_df.index.name = \"node_id\"\n",
    "\n",
    "#     # Guardar en un archivo CSV\n",
    "#     emb_df.to_csv(\"node_embeddings.csv\")\n",
    "#     np.save(\"node_embeddings.npy\", final_embeddings)\n",
    "#     print(\"Embeddings guardados en 'node_embeddings.csv'\")\n",
    "\n",
    "# emb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHAPE] (36173, 16)\n",
      "[EMBEDDING] [ 1.1019298 -0.3352208 -3.0747113  2.2287536 -0.6276562 -2.0871685\n",
      "  2.7496235 -0.1081185 -1.6965067  3.4321244 -1.2172776 -3.1097293\n",
      "  2.0906534 -2.4634714  3.2612672 -0.4141587]\n"
     ]
    }
   ],
   "source": [
    "# # Cargar embeddings\n",
    "# embeddings = np.load(\"node_embeddings.npy\")\n",
    "# print(\"[SHAPE]\",embeddings.shape)\n",
    "# print(\"[EMBEDDING]\",embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
    "Cosas a tener consideraciom:\n",
    "- GNN al crear un grafo, crea tdoos los nodos que se encuentran en el rango entregado. De esta forma pueden quedar nodos aislados, sin embargo ento causa que no se puedan ir 'actualizando' pero al agregar self_loop se actualizan con si mismos y supondremos que con ello algun patron para este tipo de nodos.\n",
    "- La entrega de embeddings finales esta en orden el ASN de valor inferios hasta el ASN de valor maximo.\n",
    "- Lo guardamso en un .csv dondde se asocia 'node_id' con su embeddings y donde node_id es el ASN del Sistema Autonomo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencia valor PAgeRank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "\n",
    "class GNNPredictLastFeat(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = dgl.nn.GraphConv(in_feats, hidden_feats)\n",
    "        self.conv2 = dgl.nn.GraphConv(hidden_feats, hidden_feats)\n",
    "        self.regressor = nn.Linear(hidden_feats, 1)  # solo predice 1 nÃºmero por nodo\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        h = F.relu(self.conv1(g, features))\n",
    "        h = F.relu(self.conv2(g, h))\n",
    "        out = self.regressor(h)  # predicciÃ³n de un valor\n",
    "        return out.squeeze(-1)   # tamaÃ±o [n_nodos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data into cached files.\n",
      "Graph(num_nodes=36580, num_edges=315774,\n",
      "      ndata_schemes={'feat': Scheme(shape=(69,), dtype=torch.float32)}\n",
      "      edata_schemes={'Relationship': Scheme(shape=(), dtype=torch.float32)})\n"
     ]
    }
   ],
   "source": [
    "gnn = GNN(debug=True)\n",
    "gnn.load_dataset(dataset_graph_path, force_reload=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitar valor a inferir\n",
    "feats = gnn.dgl_graph.ndata['feat']\n",
    "targets = feats[:, -1]\n",
    "new_feats = feats[:, :-1]\n",
    "\n",
    "gnn.dgl_graph.ndata['feat'] = new_feats\n",
    "gnn.dgl_graph = dgl.add_self_loop(gnn.dgl_graph) # FIXME:\n",
    "\n",
    "gnn.split_graph_nodes(train_size=0.8)\n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True,  True,  ...,  True, False, False])\n",
      "tensor([ True, False, False,  ..., False,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_mask = gnn.dgl_graph.train_mask\n",
    "test_mask = gnn.dgl_graph.test_mask\n",
    "\n",
    "print(train_mask)\n",
    "print(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.0177\n",
      "Epoch 1: Loss = 0.0045\n",
      "Epoch 2: Loss = 0.0078\n",
      "Epoch 3: Loss = 0.0035\n",
      "Epoch 4: Loss = 0.0010\n",
      "Epoch 5: Loss = 0.0005\n",
      "Epoch 6: Loss = 0.0004\n",
      "Epoch 7: Loss = 0.0004\n",
      "Epoch 8: Loss = 0.0003\n",
      "Epoch 9: Loss = 0.0004\n",
      "Epoch 10: Loss = 0.0004\n",
      "Epoch 11: Loss = 0.0003\n",
      "Epoch 12: Loss = 0.0001\n",
      "Epoch 13: Loss = 0.0001\n",
      "Epoch 14: Loss = 0.0001\n",
      "Epoch 15: Loss = 0.0001\n",
      "Epoch 16: Loss = 0.0001\n",
      "Epoch 17: Loss = 0.0001\n",
      "Epoch 18: Loss = 0.0001\n",
      "Epoch 19: Loss = 0.0001\n",
      "Epoch 20: Loss = 0.0001\n",
      "Epoch 21: Loss = 0.0001\n",
      "Epoch 22: Loss = 0.0000\n",
      "Epoch 23: Loss = 0.0000\n",
      "Epoch 24: Loss = 0.0000\n",
      "Epoch 25: Loss = 0.0000\n",
      "Epoch 26: Loss = 0.0000\n",
      "Epoch 27: Loss = 0.0000\n",
      "Epoch 28: Loss = 0.0000\n",
      "Epoch 29: Loss = 0.0000\n",
      "Epoch 30: Loss = 0.0000\n",
      "Epoch 31: Loss = 0.0000\n",
      "Epoch 32: Loss = 0.0000\n",
      "Epoch 33: Loss = 0.0000\n",
      "Epoch 34: Loss = 0.0000\n",
      "Epoch 35: Loss = 0.0000\n",
      "Epoch 36: Loss = 0.0000\n",
      "Epoch 37: Loss = 0.0000\n",
      "Epoch 38: Loss = 0.0000\n",
      "Epoch 39: Loss = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# -------------- Entrenamiento ------------------ #\n",
    "import torch.optim as optim\n",
    "\n",
    "# Creamos el modelo\n",
    "model = GNNPredictLastFeat(in_feats=gnn.dgl_graph.ndata['feat'].shape[1], hidden_feats=64)\n",
    "\n",
    "# Forward pass\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.MSELoss()  # Porque es regresiÃ³n\n",
    "\n",
    "for epoch in range(40):\n",
    "    model.train()\n",
    "    logits = model(gnn.dgl_graph, gnn.dgl_graph.ndata['feat'])  # predictions.shape = [n_nodes]\n",
    "    loss = F.mse_loss(logits[train_mask], targets[train_mask])    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     pred = model(gnn.dgl_graph, gnn.dgl_graph.ndata['feat'])\n",
    "    \n",
    "#     pred = (pred[test_mask] > 0.5).float()  # Convertir a 0 o 1\n",
    "#     acc = (pred == targets[test_mask]).float().mean()\n",
    "#     print(f\"Test Accuracy: {acc.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(gnn.dgl_graph, gnn.dgl_graph.ndata['feat'])\n",
    "\n",
    "mse = F.mse_loss(preds[test_mask], targets[test_mask]).item()\n",
    "print(f\"Test MSE: {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36580, 68])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "gnn.dgl_graph.ndata['feat'].shape"
=======
    "# gnn.train_g.ndata['feat'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepWalk (2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepWalk como en otros metodos de NLP donde la frecuencia de palabras tiene un comportamiento aque siguie una distribuciÃ³n de ley de potencia (Power Law Distribution). (Pocas palabras tienen una alta aparicion mientras que la mayoria raramente aparece).\n",
    "Este siguie un comportamiento similarar, donde en caminatas aleatorias son pocos los nodos que aparecen frecuentemente, mientras que la mayoria no.\n",
    "\n",
    "* Se apoyan en el mismo concepto que plantea word2vec\n",
    "* De igual manera que word2vec busca estimar la probabilidad de ocurrencia de una palabra en una frase, dadas las palabras cercanas\n",
    "\n",
    "Algoritmo:\n",
    "\n",
    "* DeepWalk genera caminos aleatorios recorriendo el grafo mÃºltiples veces desde todos los nodos con una longitud determinada.\n",
    "* Deep Walk se les llama caminos aleatorios de primer orden ya que se basan en probabilidades de transiciÃ³n de nodo-a-nodo;\n",
    "\n",
    "\n",
    "Resultados esperados:\n",
    "* Bajo la homophily hypothesis, nodos muy conectados entre sÃ­ y que pertenecen a las mismas comunidades en el grafo, deben producir embeddings cercanos. \n",
    "* Bajo la structural hypothesis, nodos cuya funciÃ³n estructural en el grafo es similar (por ejemplo, nodos que actÃºan como hub) tambiÃ©n deben producir embeddings cercanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepWalk es un algoritmo para aprender embeddings de nodos en un grafo.\n",
    "Â¿CÃ³mo funciona?\n",
    "\n",
    "    Hace caminatas aleatorias (random walks) por el grafo, partiendo de cada nodo, como si fueran frases.\n",
    "\n",
    "    Cada caminata es una secuencia de nodos, como una frase es una secuencia de palabras.\n",
    "\n",
    "    Usa Word2Vec (Skip-gram) para aprender embeddings de nodos, tratÃ¡ndolos como si fueran palabras.\n",
    "\n",
    "        Nodo = palabra\n",
    "\n",
    "        Caminata = frase\n",
    "\n",
    "        Grafo = corpus"
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guaradar el modelo\n",
    "torch.save(model.state_dict(), 'data/model_emb.pth')\n",
    "\n",
    "# Guardar los embeddings\n",
    "torch.save(h, \"data/embeddings_ribs_PageRank.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict otro\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear Embeddings otros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepWalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
=======
   "execution_count": 35,
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import DeepWalk\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SparseAdam"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 36,
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data into cached files.\n",
      "Graph(num_nodes=36580, num_edges=315774,\n",
      "      ndata_schemes={'feat': Scheme(shape=(74,), dtype=torch.float32)}\n",
      "      edata_schemes={'Relationship': Scheme(shape=(), dtype=torch.float32)})\n",
      "[ATTR SHAPE]:  torch.Size([36580, 74])\n",
      "Generando 315774 aristas negativas...\n",
      "Aristas negativas generadas: 315773\n"
     ]
    }
   ],
   "source": [
    "gnn = GNN(debug=True)\n",
    "gnn.load_dataset(dataset_graph_path, force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 64,
=======
   "execution_count": 52,
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = DeepWalk(gnn.dgl_graph,\n",
    "               emb_dim=32,        # tamaÃ±o del embedding\n",
    "               walk_length=6,     # nÃºmero de saltos por walk\n",
<<<<<<< HEAD
    "            #    context_size=5,     # tamaÃ±o de la ventana de contexto\n",
    "            #    walks_per_node=10,  # nÃºmero de walks por nodo\n",
    "            #    num_negative=5\n",
    "               )     # nÃºmero de negativos por positivo\n",
    "\n",
    "emb = DeepWalk(gnn.dgl_graph)"
=======
    "                    # tamaÃ±o de la ventana de contexto\n",
    "            #    walks_per_node=10,  # nÃºmero de walks por nodo\n",
    "            #    num_negative=5\n",
    "            # nÃºmero de negativos por positivo\n",
    ")"
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_walk max: 35760\n",
      "embedding size: 36173\n",
      "[BATCH] torch.Size([128, 40])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding size:\u001b[39m\u001b[38;5;124m\"\u001b[39m, emb\u001b[38;5;241m.\u001b[39mnode_embed\u001b[38;5;241m.\u001b[39mnum_embeddings)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[BATCH]\u001b[39m\u001b[38;5;124m\"\u001b[39m,batch_walk\u001b[38;5;241m.\u001b[39mshape )\n\u001b[0;32m---> 17\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43memb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_walk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/dgl/nn/pytorch/network_emb.py:181\u001b[0m, in \u001b[0;36mDeepWalk.forward\u001b[0;34m(self, batch_walk)\u001b[0m\n\u001b[1;32m    178\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_walk)\n\u001b[1;32m    179\u001b[0m device \u001b[38;5;241m=\u001b[39m batch_walk\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 181\u001b[0m batch_node_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_walk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_dim)\n\u001b[1;32m    182\u001b[0m batch_context_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_embed(batch_walk)\u001b[38;5;241m.\u001b[39mview(\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_dim\n\u001b[1;32m    184\u001b[0m )\n\u001b[1;32m    186\u001b[0m batch_idx_list_offset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(batch_size) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwalk_length\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GIT/TrabajoTesis/env310/lib/python3.10/site-packages/torch/nn/functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "emb = DeepWalk(gnn.dgl_graph)\n",
    "dataloader = DataLoader(torch.arange(gnn.dgl_graph.num_nodes()), \n",
    "                        batch_size=128,\n",
    "                        shuffle=True, \n",
    "                        collate_fn=emb.sample)\n",
    "\n",
    "optimizer = SparseAdam(emb.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_walk in dataloader:\n",
    "        print(\"batch_walk max:\", batch_walk.max().item())\n",
    "        print(\"embedding size:\", emb.node_embed.num_embeddings)\n",
    "\n",
    "        print(\"[BATCH]\",batch_walk.shape )\n",
    "        loss = emb(batch_walk)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader = DataLoader(torch.arange(gnn.dgl_graph.num_nodes()),\n",
    "                        batch_size=500,\n",
    "                        shuffle=True, \n",
    "                        collate_fn=emb.sample,)\n",
    "\n",
    "optimizer = SparseAdam(emb.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_walk in dataloader:\n",
    "        # print(\"[BATCH]\",batch_walk )\n",
    "        loss = emb(batch_walk)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
<<<<<<< HEAD
    "        "
=======
    "\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch_walk in dataloader:\n",
    "#         # Reemplazar -1 por un nodo vÃ¡lido (ej: nodo 0)\n",
    "#         batch_walk[batch_walk == -1] = 0\n",
    "\n",
    "#         loss = emb(batch_walk)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n"
>>>>>>> dd938f7dad20d9d83f29b8a3e6b2679fecd09c32
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE torch.Size([36580, 128])\n",
      "EMBEDDINGS tensor([[-0.1586, -0.1637,  0.1585,  ...,  0.1625, -0.1555,  0.1694],\n",
      "        [-0.2038, -0.1939,  0.2022,  ...,  0.1929, -0.1953,  0.1814],\n",
      "        [-0.1803, -0.1698,  0.1698,  ...,  0.1676, -0.1702,  0.1691],\n",
      "        ...,\n",
      "        [-0.0862, -0.0907,  0.0921,  ...,  0.0857, -0.0850,  0.0945],\n",
      "        [-0.1030, -0.1055,  0.1089,  ...,  0.0963, -0.1074,  0.0997],\n",
      "        [-0.0967, -0.0872,  0.0959,  ...,  0.0849, -0.0953,  0.0819]])\n"
     ]
    }
   ],
   "source": [
    "h = emb.node_embed.weight.detach()\n",
    "print(\"SHAPE\",h.shape)\n",
    "print(\"EMBEDDINGS\",h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los embeddings\n",
    "torch.save(h, \"data/embeddings_deepWalk.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data into cached files.\n",
      "Graph(num_nodes=36580, num_edges=315774,\n",
      "      ndata_schemes={'feat': Scheme(shape=(74,), dtype=torch.float32)}\n",
      "      edata_schemes={'Relationship': Scheme(shape=(), dtype=torch.float32)})\n",
      "[ATTR SHAPE]:  torch.Size([36580, 74])\n",
      "Generando 315774 aristas negativas...\n",
      "Aristas negativas generadas: 315773\n"
     ]
    }
   ],
   "source": [
    "gnn = GNN(debug=True)\n",
    "gnn.load_dataset(dataset_graph_path, force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5807e-05],\n",
      "        [1.7451e-05],\n",
      "        [2.1136e-05],\n",
      "        ...,\n",
      "        [4.1371e-06],\n",
      "        [4.3104e-06],\n",
      "        [4.2975e-06]])\n"
     ]
    }
   ],
   "source": [
    "# ----------- 2. Run PageRank for Graph -------------- #\n",
    "N = gnn.dgl_graph.number_of_nodes()\n",
    "DAMP = 0.85\n",
    "K = 10\n",
    "\n",
    "\n",
    "def compute_pagerank(g):\n",
    "    g.ndata[\"pv\"] = torch.ones(N) / N\n",
    "    degrees = g.out_degrees(g.nodes()).type(torch.float32)\n",
    "    for k in range(K):\n",
    "        g.ndata[\"pv\"] = g.ndata[\"pv\"] / degrees\n",
    "        g.update_all(\n",
    "            message_func=fn.copy_u(u=\"pv\", out=\"m\"),\n",
    "            reduce_func=fn.sum(msg=\"m\", out=\"pv\"),\n",
    "        )\n",
    "        g.ndata[\"pv\"]  = (1 - DAMP) / N + DAMP * g.ndata[\"pv\"]\n",
    "    g.ndata[\"pv\"]  = g.ndata[\"pv\"].unsqueeze(1)\n",
    "    return g.ndata[\"pv\"]\n",
    "\n",
    "\n",
    "pv = compute_pagerank(gnn.dgl_graph)\n",
    "gnn.dgl_graph.ndata[\"h\"] = pv  # Inicializa caracterÃ­sticas del nodo\n",
    "\n",
    "print(gnn.dgl_graph.ndata[\"h\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = gnn.dgl_graph.ndata[\"h\"]\n",
    "torch.save(h, \"data/embeddings_pageRank.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node2Vec (2016)\n",
    "\n",
    "* Surge con el fin de generalizar DeepWalk.\n",
    "* Node2Vec emplea caminos aleatorios de segundo orden, pues se basa en probabilidades de transiciÃ³n de nodo-a-nodo-a-nodo (o vÃ©rtice-a-vÃ©rtice). Es decir, avanzar hacia un nodo determinado no viene sÃ³lo dado por el nodo en el que nos encontremos, sino tambiÃ©n por el nodo anterior de donde vengamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se apoyan en el mismo concepto que plantea word2vec\n",
    "* De igual manera que word2vec busca estimar la probabilidad de ocurrencia de una palabra en una frase, dadas las palabras cercanas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node2Vec es una mejora de DeepWalk. TambiÃ©n genera caminatas y usa Word2Vec, pero:\n",
    "    Introduce dos parÃ¡metros:\n",
    "        pp: controla la probabilidad de volver atrÃ¡s (tipo DFS).\n",
    "\n",
    "        qq: controla la probabilidad de explorar localmente (tipo BFS).\n",
    "\n",
    "    AsÃ­, Node2Vec puede balancear entre exploraciÃ³n profunda (estructural) y local (de vecindad).\n",
    "\n",
    "Esto permite obtener embeddings que capturan diferentes tipos de relaciones:\n",
    "\n",
    "    Parecidos en rol (ej: puentes entre comunidades).\n",
    "\n",
    "    Parecidos en vecindad (ej: miembros de la misma comunidad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
